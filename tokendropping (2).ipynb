{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# !rm -rf \"mymodel\"\n",
        "# !git clone https://github.com/ZubinGou/math-evaluation-harness.git\n",
        "os.chdir(\"/content/math-evaluation-harness\")\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "print(os.getcwd())\n",
        "os.chdir(\"..\")\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02sSNheVnggn",
        "outputId": "44ea20f6-402f-4e08-844a-0e16450c1cd3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/ZubinGou/latex2sympy.git (from -r requirements.txt (line 16))\n",
            "  Cloning https://github.com/ZubinGou/latex2sympy.git to /tmp/pip-req-build-ej74k2lv\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/ZubinGou/latex2sympy.git /tmp/pip-req-build-ej74k2lv\n",
            "  Resolved https://github.com/ZubinGou/latex2sympy.git to commit 257b03feecbdc101acdb3c61f3eca17a8ee79731\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: vllm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (0.6.3.post1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (4.66.6)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (3.1.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (2.4.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (4.46.3)\n",
            "Requirement already satisfied: python_dateutil in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (2.8.2)\n",
            "Requirement already satisfied: sympy==1.12 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (1.12)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.11.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (4.11.1)\n",
            "Requirement already satisfied: word2number in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (1.1)\n",
            "Requirement already satisfied: Pebble in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (5.1.0)\n",
            "Requirement already satisfied: timeout-decorator in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (0.5.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy==1.12->-r requirements.txt (line 11)) (1.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from vllm->-r requirements.txt (line 3)) (5.9.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from vllm->-r requirements.txt (line 3)) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from vllm->-r requirements.txt (line 3)) (1.26.4)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from vllm->-r requirements.txt (line 3)) (2.32.3)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from vllm->-r requirements.txt (line 3)) (9.0.0)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from vllm->-r requirements.txt (line 3)) (0.20.3)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from vllm->-r requirements.txt (line 3)) (4.25.5)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from vllm->-r requirements.txt (line 3)) (3.11.10)\n",
            "Requirement already satisfied: openai>=1.40.0 in /usr/local/lib/python3.10/dist-packages (from vllm->-r requirements.txt (line 3)) (1.54.5)\n",
            "Requirement already satisfied: uvicorn[standard] in /usr/local/lib/python3.10/dist-packages (from vllm->-r requirements.txt (line 3)) (0.33.0)\n",
            "Requirement already satisfied: pydantic>=2.9 in /usr/local/lib/python3.10/dist-packages (from vllm->-r requirements.txt (line 3)) (2.10.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from vllm->-r requirements.txt (line 3)) (10.4.0)\n",
            "Requirement already satisfied: prometheus-client>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from vllm->-r requirements.txt (line 3)) (0.21.1)\n",
            "Requirement already satisfied: prometheus-fastapi-instrumentator>=7.0.0 in /usr/local/lib/python3.10/dist-packages (from vllm->-r requirements.txt (line 3)) (7.0.0)\n",
            "Requirement already satisfied: tiktoken>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from vllm->-r requirements.txt (line 3)) (0.7.0)\n",
            "Requirement already satisfied: lm-format-enforcer==0.10.6 in /usr/local/lib/python3.10/dist-packages (from vllm->-r requirements.txt (line 3)) (0.10.6)\n",
            "Requirement already satisfied: outlines<0.1,>=0.0.43 in /usr/local/lib/python3.10/dist-packages (from vllm->-r requirements.txt (line 3)) (0.0.46)\n",
            "Requirement already satisfied: typing-extensions>=4.10 in /usr/local/lib/python3.10/dist-packages (from vllm->-r requirements.txt (line 3)) (4.12.2)\n",
            "Requirement already satisfied: filelock>=3.10.4 in /usr/local/lib/python3.10/dist-packages (from vllm->-r requirements.txt (line 3)) (3.16.1)\n",
            "Requirement already satisfied: partial-json-parser in /usr/local/lib/python3.10/dist-packages (from vllm->-r requirements.txt (line 3)) (0.2.1.1.post4)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.10/dist-packages (from vllm->-r requirements.txt (line 3)) (24.0.1)\n",
            "Requirement already satisfied: msgspec in /usr/local/lib/python3.10/dist-packages (from vllm->-r requirements.txt (line 3)) (0.18.6)\n",
            "Requirement already satisfied: gguf==0.10.0 in /usr/local/lib/python3.10/dist-packages (from vllm->-r requirements.txt (line 3)) (0.10.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from vllm->-r requirements.txt (line 3)) (8.5.0)\n",
            "Requirement already satisfied: mistral-common>=1.4.4 in /usr/local/lib/python3.10/dist-packages (from mistral-common[opencv]>=1.4.4->vllm->-r requirements.txt (line 3)) (1.5.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from vllm->-r requirements.txt (line 3)) (6.0.2)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from vllm->-r requirements.txt (line 3)) (0.8.0)\n",
            "Requirement already satisfied: compressed-tensors==0.6.0 in /usr/local/lib/python3.10/dist-packages (from vllm->-r requirements.txt (line 3)) (0.6.0)\n",
            "Requirement already satisfied: ray>=2.9 in /usr/local/lib/python3.10/dist-packages (from vllm->-r requirements.txt (line 3)) (2.40.0)\n",
            "Requirement already satisfied: nvidia-ml-py in /usr/local/lib/python3.10/dist-packages (from vllm->-r requirements.txt (line 3)) (12.560.30)\n",
            "Requirement already satisfied: torchvision==0.19 in /usr/local/lib/python3.10/dist-packages (from vllm->-r requirements.txt (line 3)) (0.19.0)\n",
            "Requirement already satisfied: xformers==0.0.27.post2 in /usr/local/lib/python3.10/dist-packages (from vllm->-r requirements.txt (line 3)) (0.0.27.post2)\n",
            "Requirement already satisfied: fastapi!=0.113.*,!=0.114.0,>=0.107.0 in /usr/local/lib/python3.10/dist-packages (from vllm->-r requirements.txt (line 3)) (0.115.6)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 6)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 6)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 6)) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 6)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 6)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 6)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 6)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 6)) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 6)) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 6)) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 6)) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 6)) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 6)) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 6)) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 6)) (3.0.0)\n",
            "Requirement already satisfied: interegular>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from lm-format-enforcer==0.10.6->vllm->-r requirements.txt (line 3)) (0.3.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lm-format-enforcer==0.10.6->vllm->-r requirements.txt (line 3)) (24.2)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->-r requirements.txt (line 6)) (12.6.85)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 5)) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 5)) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 5)) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 5)) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 5)) (0.70.16)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 5)) (0.26.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 7)) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 7)) (0.4.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python_dateutil->-r requirements.txt (line 8)) (1.17.0)\n",
            "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from fastapi!=0.113.*,!=0.114.0,>=0.107.0->vllm->-r requirements.txt (line 3)) (0.41.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm->-r requirements.txt (line 3)) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm->-r requirements.txt (line 3)) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm->-r requirements.txt (line 3)) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm->-r requirements.txt (line 3)) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm->-r requirements.txt (line 3)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm->-r requirements.txt (line 3)) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm->-r requirements.txt (line 3)) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm->-r requirements.txt (line 3)) (1.18.3)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.21.1 in /usr/local/lib/python3.10/dist-packages (from mistral-common>=1.4.4->mistral-common[opencv]>=1.4.4->vllm->-r requirements.txt (line 3)) (4.23.0)\n",
            "Requirement already satisfied: opencv-python-headless<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mistral-common[opencv]>=1.4.4->vllm->-r requirements.txt (line 3)) (4.10.0.84)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.40.0->vllm->-r requirements.txt (line 3)) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.40.0->vllm->-r requirements.txt (line 3)) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.40.0->vllm->-r requirements.txt (line 3)) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.40.0->vllm->-r requirements.txt (line 3)) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.40.0->vllm->-r requirements.txt (line 3)) (1.3.1)\n",
            "Requirement already satisfied: lark in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm->-r requirements.txt (line 3)) (1.2.2)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm->-r requirements.txt (line 3)) (1.6.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm->-r requirements.txt (line 3)) (3.1.0)\n",
            "Requirement already satisfied: diskcache in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm->-r requirements.txt (line 3)) (5.6.3)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm->-r requirements.txt (line 3)) (0.60.0)\n",
            "Requirement already satisfied: referencing in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm->-r requirements.txt (line 3)) (0.35.1)\n",
            "Requirement already satisfied: pycountry in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm->-r requirements.txt (line 3)) (24.6.1)\n",
            "Requirement already satisfied: pyairports in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm->-r requirements.txt (line 3)) (2.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.9->vllm->-r requirements.txt (line 3)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.9->vllm->-r requirements.txt (line 3)) (2.27.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm->-r requirements.txt (line 3)) (8.1.7)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm->-r requirements.txt (line 3)) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->vllm->-r requirements.txt (line 3)) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->vllm->-r requirements.txt (line 3)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->vllm->-r requirements.txt (line 3)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->vllm->-r requirements.txt (line 3)) (2024.8.30)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->vllm->-r requirements.txt (line 3)) (3.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r requirements.txt (line 6)) (3.0.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r requirements.txt (line 5)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r requirements.txt (line 5)) (2024.2)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->vllm->-r requirements.txt (line 3)) (0.14.0)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->vllm->-r requirements.txt (line 3)) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->vllm->-r requirements.txt (line 3)) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->vllm->-r requirements.txt (line 3)) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->vllm->-r requirements.txt (line 3)) (1.0.3)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->vllm->-r requirements.txt (line 3)) (14.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.40.0->vllm->-r requirements.txt (line 3)) (1.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai>=1.40.0->vllm->-r requirements.txt (line 3)) (1.0.7)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.21.1->mistral-common>=1.4.4->mistral-common[opencv]>=1.4.4->vllm->-r requirements.txt (line 3)) (2024.10.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.21.1->mistral-common>=1.4.4->mistral-common[opencv]>=1.4.4->vllm->-r requirements.txt (line 3)) (0.22.3)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->outlines<0.1,>=0.0.43->vllm->-r requirements.txt (line 3)) (0.43.0)\n",
            "/content/math-evaluation-harness\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#forward dropping\n",
        "from transformers import AutoConfig\n",
        "from transformers.models.llama.modeling_llama import *\n",
        "import random\n",
        "from typing import List, Tuple\n",
        "\n",
        "class FilteringLlamaModel(LlamaModel):\n",
        "\n",
        "    # def filter_tokens(self, hidden_states: torch.Tensor, attention_mask: torch.Tensor, filtering_ratio: float, layer_outputs: List[torch.Tensor]) -> Tuple[torch.Tensor, torch.Tensor, List[int], torch.Tensor]:\n",
        "\n",
        "    #   valid_tokens_mask = attention_mask.bool().squeeze(0)\n",
        "    #   hidden_states = hidden_states[:, valid_tokens_mask, :]\n",
        "\n",
        "\n",
        "    #   num_tokens = hidden_states.shape[1]\n",
        "    #   num_to_keep = int(num_tokens * (1 - filtering_ratio))\n",
        "\n",
        "\n",
        "    #   all_indices = torch.arange(num_tokens, device=hidden_states.device)\n",
        "    #   keep_indices = random.sample(range(num_tokens), num_to_keep)\n",
        "    #   keep_indices_tensor = torch.tensor(keep_indices, device=hidden_states.device)\n",
        "\n",
        "    #   keep_original_indices = all_indices[keep_indices_tensor]\n",
        "    #   dropped_indices = all_indices[~keep_indices_tensor]\n",
        "\n",
        "    #   new_attention_mask = attention_mask.clone()\n",
        "    #   new_attention_mask[:, dropped_indices] = 0\n",
        "    #   return new_attention_mask\n",
        "\n",
        "    # def filter_tokens(self, hidden_states: torch.Tensor, attention_mask: torch.Tensor, filtering_ratio: float, layer_outputs: List[torch.Tensor]) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "    #   # Get attention values\n",
        "    #   attention_values = layer_outputs[1]  # shape: [batch_size, num_heads, seq_len, seq_len]\n",
        "\n",
        "    #   # Calculate average attention score for each token\n",
        "    #   mean_attention = attention_values.mean(dim=(1, 2)).squeeze(0)  # shape: [seq_len]\n",
        "\n",
        "    #   valid_tokens_mask = attention_mask.bool().squeeze(0)\n",
        "    #   mean_attention = mean_attention[valid_tokens_mask]\n",
        "\n",
        "    #   num_tokens = mean_attention.shape[0]\n",
        "    #   num_to_drop = int(num_tokens * filtering_ratio)\n",
        "    #   num_to_drop_randomly = int(num_to_drop * 0.2)  # 20% of dropped tokens\n",
        "    #   num_to_drop_attention = num_to_drop - num_to_drop_randomly\n",
        "\n",
        "    #   # Randomly select tokens to drop\n",
        "    #   all_indices = set(range(num_tokens))\n",
        "    #   random_drop_indices = set(random.sample(range(num_tokens), num_to_drop_randomly))\n",
        "\n",
        "    #   # Select remaining tokens to drop based on attention scores, excluding randomly dropped tokens\n",
        "    #   remaining_indices = list(all_indices - random_drop_indices)\n",
        "    #   remaining_mean_attention = mean_attention[remaining_indices]\n",
        "    #   _, attention_drop_indices = torch.topk(remaining_mean_attention, num_to_drop_attention, largest=False)\n",
        "    #   attention_drop_indices = set(remaining_indices[i] for i in attention_drop_indices.tolist())\n",
        "\n",
        "    #   # Combine randomly dropped and attention-based dropped indices\n",
        "    #   drop_indices = random_drop_indices.union(attention_drop_indices)\n",
        "    #   keep_indices = list(all_indices - drop_indices)\n",
        "\n",
        "    #   # Sort keep_indices to maintain original order\n",
        "    #   keep_indices.sort()\n",
        "    #   keep_indices = torch.tensor(keep_indices, device=attention_mask.device)\n",
        "\n",
        "    #   # Create a new attention mask\n",
        "    #   new_attention_mask = torch.zeros_like(attention_mask)\n",
        "    #   new_attention_mask[:, keep_indices] = attention_mask[:, keep_indices]\n",
        "\n",
        "    #   return new_attention_mask\n",
        "\n",
        "    # def add_back_tokens(self, hidden_states: torch.Tensor, original_tokens: torch.Tensor, dropped_indices: List[int], attention_mask: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "    #   # 将原始 tokens 放回到 hidden_states 中\n",
        "    #   # for batch_idx in range(hidden_states.shape[0]):\n",
        "    #   #     hidden_states[batch_idx, dropped_indices, :] = original_tokens[batch_idx]\n",
        "\n",
        "    #   # 恢复 attention_mask\n",
        "    #   attention_mask[:, dropped_indices] = 1\n",
        "\n",
        "    #   return hidden_states, attention_mask\n",
        "\n",
        "    def filter_tokens(self,hidden_states: torch.Tensor, attention_mask: torch.Tensor, filtering_ratio: float, layer_outputs: List[torch.Tensor]) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        # Get attention values\n",
        "        attention_values = layer_outputs[1]  # shape: [batch_size, num_heads, seq_len, seq_len]\n",
        "\n",
        "        # Calculate average attention score for each token\n",
        "        mean_attention = attention_values.mean(dim=(1, 2)).squeeze(0)  # shape: [seq_len]\n",
        "\n",
        "        valid_tokens_mask = attention_mask.bool().squeeze(0)\n",
        "        mean_attention = mean_attention[valid_tokens_mask]\n",
        "\n",
        "        num_tokens = mean_attention.shape[0]\n",
        "        num_to_keep = int(num_tokens * (1 - filtering_ratio))\n",
        "\n",
        "        # Select tokens to keep based on attention scores\n",
        "        _, keep_indices = torch.topk(mean_attention, num_to_keep, largest=True)\n",
        "        keep_indices, _ = torch.sort(keep_indices)  # maintain original order\n",
        "\n",
        "        # Create a new attention mask\n",
        "        new_attention_mask = torch.zeros_like(attention_mask)\n",
        "        new_attention_mask[:, keep_indices] = attention_mask[:, keep_indices]\n",
        "\n",
        "        return new_attention_mask\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: torch.LongTensor = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        position_ids: Optional[torch.LongTensor] = None,\n",
        "        past_key_values: Optional[Union[Cache, List[torch.FloatTensor]]] = None,\n",
        "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
        "        use_cache: Optional[bool] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = None,\n",
        "        cache_position: Optional[torch.LongTensor] = None,\n",
        "    ) -> Union[Tuple, BaseModelOutputWithPast]:\n",
        "        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
        "        output_attentions = True\n",
        "        output_hidden_states = (\n",
        "            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
        "        )\n",
        "        use_cache = use_cache if use_cache is not None else self.config.use_cache\n",
        "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
        "\n",
        "        if (input_ids is None) ^ (inputs_embeds is not None):\n",
        "            raise ValueError(\n",
        "                \"You cannot specify both input_ids and inputs_embeds at the same time, and must specify either one\"\n",
        "            )\n",
        "\n",
        "        if self.gradient_checkpointing and self.training and use_cache:\n",
        "            logger.warning_once(\n",
        "                \"`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\"\n",
        "            )\n",
        "            use_cache = False\n",
        "\n",
        "        if inputs_embeds is None:\n",
        "            inputs_embeds = self.embed_tokens(input_ids)\n",
        "\n",
        "        return_legacy_cache = False\n",
        "        if (\n",
        "            use_cache and not isinstance(past_key_values, Cache) and not self.training\n",
        "        ):  # kept for BC (non `Cache` `past_key_values` inputs)\n",
        "            return_legacy_cache = True\n",
        "            past_key_values = DynamicCache.from_legacy_cache(past_key_values)\n",
        "            logger.warning_once(\n",
        "                \"We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. \"\n",
        "                \"Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\"\n",
        "            )\n",
        "\n",
        "        if cache_position is None:\n",
        "            past_seen_tokens = past_key_values.get_seq_length() if past_key_values is not None else 0\n",
        "            cache_position = torch.arange(\n",
        "                past_seen_tokens, past_seen_tokens + inputs_embeds.shape[1], device=inputs_embeds.device\n",
        "            )\n",
        "        if position_ids is None:\n",
        "            position_ids = cache_position.unsqueeze(0)\n",
        "\n",
        "        causal_mask = self._update_causal_mask(\n",
        "            attention_mask, inputs_embeds, cache_position, past_key_values, output_attentions\n",
        "        )\n",
        "        hidden_states = inputs_embeds\n",
        "\n",
        "        # create position embeddings to be shared across the decoder layers\n",
        "        position_embeddings = self.rotary_emb(hidden_states, position_ids)\n",
        "\n",
        "        # decoder layers\n",
        "        all_hidden_states = () if output_hidden_states else None\n",
        "        all_self_attns = () if output_attentions else None\n",
        "        next_decoder_cache = None\n",
        "\n",
        "        # Assuming we filter at [filtering_layers] layers with [filtering_ratio]\n",
        "        # Todo: input filtering_layers and filtering_ratio as parameters\n",
        "        filtering_layers = [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
        "        filtering_ratio = 0.3\n",
        "        # print(output_attentions)\n",
        "        for layer_index in range(len(self.layers)):\n",
        "\n",
        "            decoder_layer = self.layers[layer_index]\n",
        "\n",
        "            if layer_index in filtering_layers:\n",
        "                \"\"\"\n",
        "                Todo: Filter the tokens based on attention values, implement the filter_tokens function\n",
        "                \"\"\"\n",
        "\n",
        "                tmp_attention_mask = attention_mask.clone()\n",
        "                attention_mask = self.filter_tokens(hidden_states,attention_mask, filtering_ratio, layer_outputs)\n",
        "\n",
        "\n",
        "                # 更新 causal_mask\n",
        "                causal_mask = self._update_causal_mask(attention_mask, hidden_states, cache_position, past_key_values, output_attentions)\n",
        "                pass\n",
        "\n",
        "            if output_hidden_states:\n",
        "                all_hidden_states += (hidden_states,)\n",
        "\n",
        "            if self.gradient_checkpointing and self.training:\n",
        "                layer_outputs = self._gradient_checkpointing_func(\n",
        "                    decoder_layer.__call__,\n",
        "                    hidden_states,\n",
        "                    causal_mask,\n",
        "                    position_ids,\n",
        "                    past_key_values,\n",
        "                    output_attentions,\n",
        "                    use_cache,\n",
        "                    cache_position,\n",
        "                    position_embeddings,\n",
        "                )\n",
        "            else:\n",
        "                layer_outputs = decoder_layer(\n",
        "                    hidden_states,\n",
        "                    attention_mask=causal_mask,\n",
        "                    position_ids=position_ids,\n",
        "                    past_key_value=past_key_values,\n",
        "                    output_attentions=output_attentions,\n",
        "                    use_cache=use_cache,\n",
        "                    cache_position=cache_position,\n",
        "                    position_embeddings=position_embeddings,\n",
        "                )\n",
        "\n",
        "            hidden_states = layer_outputs[0]\n",
        "\n",
        "            if layer_index in filtering_layers:\n",
        "                \"\"\"\n",
        "                Todo: Add back the filtered tokens to hidden_states for next layer's filtering\n",
        "                (i.e., we filter different tokens heterogeneously at different layers)\n",
        "                \"\"\"\n",
        "\n",
        "                attention_mask = tmp_attention_mask.clone()\n",
        "\n",
        "\n",
        "                causal_mask = self._update_causal_mask(attention_mask, hidden_states, cache_position, past_key_values, output_attentions)\n",
        "\n",
        "                pass\n",
        "\n",
        "            if use_cache:\n",
        "                next_decoder_cache = layer_outputs[2 if output_attentions else 1]\n",
        "\n",
        "            if output_attentions:\n",
        "                all_self_attns += (layer_outputs[1],)\n",
        "\n",
        "        hidden_states = self.norm(hidden_states)\n",
        "\n",
        "        # add hidden states from the last decoder layer\n",
        "        if output_hidden_states:\n",
        "            all_hidden_states += (hidden_states,)\n",
        "\n",
        "        next_cache = next_decoder_cache if use_cache else None\n",
        "        if return_legacy_cache:\n",
        "            next_cache = next_cache.to_legacy_cache()\n",
        "\n",
        "        if not return_dict:\n",
        "            return tuple(v for v in [hidden_states, next_cache, all_hidden_states, all_self_attns] if v is not None)\n",
        "        return BaseModelOutputWithPast(\n",
        "            last_hidden_state=hidden_states,\n",
        "            past_key_values=next_cache,\n",
        "            hidden_states=all_hidden_states,\n",
        "            attentions=all_self_attns,\n",
        "        )\n",
        "\n",
        "\n",
        "class FilteringLlamaForCausalLM(LlamaForCausalLM):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super(LlamaForCausalLM, self).__init__(config)\n",
        "\n",
        "        self.model = FilteringLlamaModel(config)\n",
        "        self.vocab_size = config.vocab_size\n",
        "        self.lm_head = nn.Linear(config.hidden_size, config.vocab_size, bias=False)\n",
        "\n",
        "        # Initialize weights and apply final processing\n",
        "        self.post_init()\n",
        "\n",
        "\n",
        "\n",
        "tiny_llama_config = AutoConfig.from_pretrained(\"TinyLlama/TinyLlama_v1.1\")\n",
        "\n",
        "filtering_llama = FilteringLlamaForCausalLM(tiny_llama_config)\n",
        "\n",
        "\n",
        "print(filtering_llama)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhtO_QPdaznA",
        "outputId": "1f91a9a6-709c-4003-ccfc-cd93a1399280"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FilteringLlamaForCausalLM(\n",
            "  (model): FilteringLlamaModel(\n",
            "    (embed_tokens): Embedding(32000, 2048)\n",
            "    (layers): ModuleList(\n",
            "      (0-21): 22 x LlamaDecoderLayer(\n",
            "        (self_attn): LlamaSdpaAttention(\n",
            "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
            "          (k_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
            "          (v_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
            "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
            "          (rotary_emb): LlamaRotaryEmbedding()\n",
            "        )\n",
            "        (mlp): LlamaMLP(\n",
            "          (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
            "          (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
            "          (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n",
            "          (act_fn): SiLU()\n",
            "        )\n",
            "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
            "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
            "      )\n",
            "    )\n",
            "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
            "    (rotary_emb): LlamaRotaryEmbedding()\n",
            "  )\n",
            "  (lm_head): Linear(in_features=2048, out_features=32000, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /tmp/*\n",
        "# from google.colab import drive\n",
        "# drive.cache_clear()\n",
        "# del drive\n",
        "import gc\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "UTNGOH9mYIlp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb5e4fa7-a5a5-4a3a-8242-28bd1071c13b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/tmp/colab_runtime.sock': Device or resource busy\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "S7JFJaL6bV2L"
      },
      "outputs": [],
      "source": [
        "#utils\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def collate_fn(batch):\n",
        "    longest = max([len(x['input_ids']) for x in batch])\n",
        "    result = {\"token_size\": [len(x['input_ids']) for x in batch]}\n",
        "    new_input_ids = np.stack([x[\"input_ids\"] + [0] * (longest-len(x[\"input_ids\"])) for x in batch])\n",
        "    new_attention_mask = np.stack([x[\"attention_mask\"] + [0] * (longest-len(x[\"attention_mask\"])) for x in batch])\n",
        "    result[\"input_ids\"] = torch.from_numpy(new_input_ids)\n",
        "    result[\"attention_mask\"] = torch.from_numpy(new_attention_mask)\n",
        "    if \"text\" in batch[0]:\n",
        "        result[\"text\"] = [x[\"text\"] for x in batch]\n",
        "    if \"ref_loss\" in batch[0]:\n",
        "        result[\"ref_loss\"] = [x[\"ref_loss\"] for x in batch]\n",
        "    return result\n",
        "\n",
        "def token_filter_loss(inputs, logits, attention_mask=None, ref_loss=None, dropping_strategy=None, drop_rate=None):\n",
        "    loss = causal_modeling_loss(inputs, logits, attention_mask)\n",
        "    if ref_loss is not None:\n",
        "        for i in range(len(ref_loss)):\n",
        "            ref_loss[i] = [0.0] * (len(loss[i])-len(ref_loss[i])) + ref_loss[i]\n",
        "        ref_mask = token_dropping_mask(loss, torch.asarray(ref_loss).to('cuda'), attention_mask, strategy=dropping_strategy, drop_rate=drop_rate)\n",
        "        loss = torch.multiply(loss, ref_mask)\n",
        "        loss_per_sample = loss.sum(-1) / ref_mask[..., 1:].sum(-1)\n",
        "    else:\n",
        "        if attention_mask is not None:\n",
        "            loss_per_sample = loss.sum(-1) / attention_mask[..., 1:].sum(-1)\n",
        "        else:\n",
        "            loss_per_sample = loss.mean(-1)\n",
        "    return loss_per_sample.mean()\n",
        "\n",
        "def evaluate(model, eval_dataloader, accelerator):\n",
        "    model.eval()\n",
        "    losses = []\n",
        "    counter = 0\n",
        "    for step, batch in enumerate(eval_dataloader):\n",
        "        with torch.no_grad():\n",
        "            logits = model(batch[\"input_ids\"]).logits\n",
        "            loss = token_filter_loss(batch[\"input_ids\"], logits, attention_mask=batch[\"attention_mask\"])\n",
        "        counter += batch[\"input_ids\"].size(0)\n",
        "        losses.append(accelerator.gather(loss))\n",
        "    accelerator.wait_for_everyone()\n",
        "    loss = torch.mean(torch.cat(losses, 0))\n",
        "    try:\n",
        "        perplexity = torch.exp(loss)\n",
        "    except OverflowError:\n",
        "        perplexity = float(\"inf\")\n",
        "    return loss.item(), perplexity.item()\n",
        "\n",
        "def causal_modeling_loss(inputs, logits, attention_mask=None):\n",
        "    # Shift so that tokens < n predict n\n",
        "    shift_labels = inputs[..., 1:].contiguous()\n",
        "    shift_logits = logits[..., :-1, :].contiguous()\n",
        "    # Calculate per-token loss\n",
        "    loss_fct = torch.nn.CrossEntropyLoss(reduce=False)\n",
        "    loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
        "    if attention_mask is not None:\n",
        "        # Filter out padded tokens\n",
        "        # loss = loss.where((attention_mask[..., 1:]==1).view(-1), torch.tensor(0.0))\n",
        "        loss = torch.multiply(loss, attention_mask[..., 1:].reshape(-1))\n",
        "    # Resize and average loss per sample\n",
        "    # loss_per_sample = loss.view(shift_logits.size(0), shift_logits.size(1)).sum(-1) / attention_mask[..., 1:].sum(-1)\n",
        "    return loss.view(shift_logits.size(0), shift_logits.size(1))\n",
        "\n",
        "def token_dropping_mask(loss, ref_loss, attention_mask, strategy=\"fixed\", drop_rate=None):\n",
        "    loss_diff = loss - ref_loss\n",
        "    if strategy == \"fixed\":\n",
        "        # assert drop_rate is not None, \"Drop rate must be provided for fixed strategy.\"\n",
        "\n",
        "        ref_mask = torch.ones_like(loss)\n",
        "        # Use torch.topk for better efficiency\n",
        "        k = int(drop_rate * loss.shape[1])\n",
        "        _, indices = torch.topk(loss_diff, k, largest=False)\n",
        "        ref_mask.scatter_(1, indices, 0)\n",
        "        return ref_mask\n",
        "    elif strategy == \"dynamic\":\n",
        "\n",
        "        threshold = 0.1\n",
        "        ref_mask = torch.where(loss_diff < threshold, 0, 1).float()\n",
        "        # 限制丢弃比例不超过 drop_rate\n",
        "        if drop_rate < 1.0:\n",
        "            for i in range(loss_diff.size(0)):\n",
        "                loss_diff_sample = loss_diff[i, :]\n",
        "                ref_mask_sample = ref_mask[i, :]\n",
        "                current_drop = torch.sum(ref_mask_sample == 0).item()\n",
        "                max_drop = int(drop_rate * loss_diff_sample.size(0))\n",
        "                if current_drop > max_drop:\n",
        "                    sorted_indices = torch.argsort(loss_diff_sample)\n",
        "                    ref_mask_sample = torch.ones_like(ref_mask_sample)\n",
        "                    ref_mask_sample[sorted_indices[:max_drop]] = 0\n",
        "                ref_mask[i, :] = ref_mask_sample\n",
        "        return ref_mask\n",
        "    elif strategy == \"std\":\n",
        "        mean = torch.mean(loss_diff, dim=1, keepdim=True)\n",
        "        std = torch.std(loss_diff, dim=1, keepdim=True)\n",
        "        std_multiplier = 1.5\n",
        "        threshold = mean - std_multiplier * std\n",
        "        ref_mask = torch.where(loss_diff < threshold, 0, 1).float()\n",
        "        # 限制丢弃比例不超过 drop_rate\n",
        "        if drop_rate < 1.0:\n",
        "            for i in range(loss_diff.size(0)):\n",
        "                loss_diff_sample = loss_diff[i, :]\n",
        "                ref_mask_sample = ref_mask[i, :]\n",
        "                current_drop = torch.sum(ref_mask_sample == 0).item()\n",
        "                max_drop = int(drop_rate * loss_diff_sample.size(0))\n",
        "                if current_drop > max_drop:\n",
        "                    sorted_indices = torch.argsort(loss_diff_sample)\n",
        "                    ref_mask_sample = torch.ones_like(ref_mask_sample)\n",
        "                    ref_mask_sample[sorted_indices[:max_drop]] = 0\n",
        "                ref_mask[i, :] = ref_mask_sample\n",
        "    return ref_mask\n",
        "\n",
        "\n",
        "def tokenized_prompts(tokenizer, prompts=None, tokenizer_args: dict = {}, input_ids=None):\n",
        "    assert input_ids is not None or prompts is not None, \"Either prompts or inputs should be provided.\"\n",
        "    if input_ids is None:\n",
        "        input_ids = tokenizer(prompts, **tokenizer_args)['input_ids']\n",
        "    return [\n",
        "        [tokenizer.decode(input_ids[batch_id][i]).strip(\" \")\n",
        "        for i in range(len(input_ids[batch_id]))]\n",
        "        for batch_id in range(len(input_ids))\n",
        "    ]\n",
        "\n",
        "def update_token_index(ref_token_list, str_index, token_index):\n",
        "    pre_length, ti = token_index\n",
        "    while (pre_length + len(ref_token_list[ti])) < str_index:\n",
        "        pre_length += len(ref_token_list[ti])\n",
        "        ti += 1\n",
        "    return [pre_length, ti]\n",
        "\n",
        "def align_ref_target_tokens(ref_tokens, target_tokens, ref_loss):\n",
        "    aligned_losses = []\n",
        "    for k in range(len(ref_tokens)):\n",
        "        # t1 = time.time()\n",
        "        total_operations = 0\n",
        "        ref_tokens_str = \"\".join(ref_tokens[k])\n",
        "        target_tokens_str = \"\".join(target_tokens[k])\n",
        "        if ref_tokens_str != target_tokens_str:\n",
        "            ref_tokens_str_index = 0\n",
        "            target_tokens_str_index = 0\n",
        "            ref_token_index = [-1, 0]\n",
        "            while True:\n",
        "                # Find the first mismatch\n",
        "                while ref_tokens_str_index<len(ref_tokens_str) and \\\n",
        "                target_tokens_str_index<len(target_tokens_str) and \\\n",
        "                ref_tokens_str[ref_tokens_str_index] == target_tokens_str[target_tokens_str_index]:\n",
        "                    ref_tokens_str_index += 1\n",
        "                    target_tokens_str_index += 1\n",
        "\n",
        "                # Chech whether the unprocessed ref or target string is empty\n",
        "                if ref_tokens_str_index >= len(ref_tokens_str) or target_tokens_str_index >= len(target_tokens_str):\n",
        "                    if ref_tokens_str_index < len(ref_tokens_str):\n",
        "                        # Delete the remaining tokens\n",
        "                        del_ref_length = len(ref_tokens_str) - ref_tokens_str_index\n",
        "                        deleted_len = 0\n",
        "                        while deleted_len < del_ref_length:\n",
        "                            if (del_ref_length - deleted_len) >= len(ref_tokens[k][-1]):\n",
        "                                deleted_len += len(ref_tokens[k].pop(-1))\n",
        "                                ref_loss[k].pop(-1)\n",
        "                            else:\n",
        "                                ref_tokens[k][-1] = ref_tokens[k][-1][:-(del_ref_length-deleted_len)]\n",
        "                                deleted_len = del_ref_length\n",
        "                    elif target_tokens_str_index < len(target_tokens_str):\n",
        "                        # Insert the remaining tokens\n",
        "                        ref_tokens[k][-1] += target_tokens_str[target_tokens_str_index:]\n",
        "                    break\n",
        "\n",
        "                # Compute the edit distance\n",
        "                process_size = min(32, len(ref_tokens_str)-ref_tokens_str_index, len(target_tokens_str)-target_tokens_str_index)\n",
        "                edit_distance = np.zeros((process_size + 1, process_size + 1))\n",
        "                for i in range(edit_distance.shape[0]):\n",
        "                    for j in range(edit_distance.shape[1]):\n",
        "                        if i == 0:\n",
        "                            edit_distance[i][j] = j\n",
        "                        elif j == 0:\n",
        "                            edit_distance[i][j] = i\n",
        "                        elif ref_tokens_str[ref_tokens_str_index:][i - 1] == target_tokens_str[target_tokens_str_index:][j - 1]:\n",
        "                            edit_distance[i][j] = edit_distance[i - 1][j - 1]\n",
        "                        else:\n",
        "                            edit_distance[i][j] = 1 + min(edit_distance[i - 1][j], edit_distance[i][j - 1], edit_distance[i - 1][j - 1])\n",
        "                # Get the edit operations\n",
        "                edit_operations = []\n",
        "                i, j = edit_distance.shape[0]-1, edit_distance.shape[1]-1\n",
        "                while i > 0 and j > 0:\n",
        "                    if ref_tokens_str[ref_tokens_str_index:][i - 1] == target_tokens_str[target_tokens_str_index:][j - 1]:\n",
        "                        edit_operations.append([1, i-1, j-1])  # unchange\n",
        "                        i -= 1\n",
        "                        j -= 1\n",
        "                    elif edit_distance[i][j] == edit_distance[i - 1][j - 1] + 1:\n",
        "                        edit_operations.append([2, i-1, j-1])  # substitute\n",
        "                        i -= 1\n",
        "                        j -= 1\n",
        "                    elif edit_distance[i][j] == edit_distance[i - 1][j] + 1:\n",
        "                        edit_operations.append([3, i-1, j-1])  # delete\n",
        "                        i -= 1\n",
        "                    elif edit_distance[i][j] == edit_distance[i][j - 1] + 1:\n",
        "                        edit_operations.append([4, i-1, j-1])  # insert\n",
        "                        j -= 1\n",
        "                while i > 0:\n",
        "                    edit_operations.append([3, i-1, j-1])  # delete\n",
        "                    i -= 1\n",
        "                while j > 0:\n",
        "                    edit_operations.append([4, i-1, j-1])  # insert\n",
        "                    j -= 1\n",
        "                # edit_operations.reverse()\n",
        "                # edit_operations = edit_operations[::-1]\n",
        "\n",
        "                edit_distance_reversed = []\n",
        "                for i in range(len(edit_operations)-1, -1, -1):\n",
        "                    edit_distance_reversed.append(edit_operations[i])\n",
        "                edit_operations = edit_distance_reversed\n",
        "\n",
        "                num_del = 0\n",
        "                num_insert = 0\n",
        "                # Remove the last insert and delete\n",
        "                l = len(edit_operations) - 1\n",
        "                while edit_operations[l][0] == 3 or edit_operations[l][0] == 4:\n",
        "                    l -= 1\n",
        "                edit_operations = edit_operations[:l+1]\n",
        "\n",
        "                for i in range(len(edit_operations)):\n",
        "                    op, _, jj = edit_operations[i]\n",
        "                    if op == 2:\n",
        "                        # Find the token index\n",
        "                        ref_token_index = update_token_index(ref_tokens[k], ref_tokens_str_index+i, ref_token_index)\n",
        "                        # Get the token and update\n",
        "                        ref_token_tmp = ref_tokens[k][ref_token_index[1]]\n",
        "                        ref_token_tmp = ref_token_tmp[:ref_tokens_str_index+i-ref_token_index[0]-1] + target_tokens_str[target_tokens_str_index+jj] + ref_token_tmp[ref_tokens_str_index+i-ref_token_index[0]:]\n",
        "                        # Update the token list and cooresponding string\n",
        "                        ref_tokens[k][ref_token_index[1]] = ref_token_tmp\n",
        "                        ref_tokens_str = ref_tokens_str[:ref_tokens_str_index+i] + target_tokens_str[target_tokens_str_index+jj] + ref_tokens_str[ref_tokens_str_index+i+1:]\n",
        "                    if op == 3:\n",
        "                        num_del += 1\n",
        "                        # Find the token index\n",
        "                        ref_token_index = update_token_index(ref_tokens[k], ref_tokens_str_index+i, ref_token_index)\n",
        "                        # Get the token\n",
        "                        ref_token_tmp = ref_tokens[k][ref_token_index[1]]\n",
        "                        # Update the token list and cooresponding string\n",
        "                        ref_tokens[k][ref_token_index[1]] = ref_token_tmp[:ref_tokens_str_index+i-ref_token_index[0]-1] + ref_token_tmp[ref_tokens_str_index+i-ref_token_index[0]:]\n",
        "                        ref_tokens_str = ref_tokens_str[:ref_tokens_str_index+i] + ref_tokens_str[ref_tokens_str_index+i+1:]\n",
        "                        ref_tokens_str_index -= 1\n",
        "                    if op == 4:\n",
        "                        num_insert += 1\n",
        "                        # Find the token index\n",
        "                        ref_token_index = update_token_index(ref_tokens[k], ref_tokens_str_index+i, ref_token_index)\n",
        "                        # Get the token and update\n",
        "                        ref_token_tmp = ref_tokens[k][ref_token_index[1]]\n",
        "                        ref_token_tmp = ref_token_tmp[:ref_tokens_str_index+i-ref_token_index[0]-1] + target_tokens_str[target_tokens_str_index+jj] + ref_token_tmp[ref_tokens_str_index+i-ref_token_index[0]-1:]\n",
        "                        # Update the token list and cooresponding string\n",
        "                        ref_tokens[k][ref_token_index[1]] = ref_token_tmp\n",
        "                        ref_tokens_str = ref_tokens_str[:ref_tokens_str_index+i] + target_tokens_str[target_tokens_str_index+jj] + ref_tokens_str[ref_tokens_str_index+i:]\n",
        "\n",
        "                # Accumulate the index\n",
        "                ref_tokens_str_index += (process_size)\n",
        "                target_tokens_str_index += (process_size - num_del)\n",
        "\n",
        "                total_operations = total_operations + num_del + num_insert\n",
        "\n",
        "                # Debug information\n",
        "                # print(ref_tokens_str[ref_tokens_str_index:ref_tokens_str_index+10], target_tokens_str[target_tokens_str_index:target_tokens_str_index+10])\n",
        "                # print(ref_tokens_str[:ref_tokens_str_index] == target_tokens_str[:target_tokens_str_index])\n",
        "                # print(\"Mathching Process\")\n",
        "\n",
        "        # assert len(ref_loss[k]) == (len(ref_tokens[k]) - 1), f\"{len(ref_loss[k])} != {len(ref_tokens[k])-1}\"\n",
        "        # assert \"\".join(ref_tokens[k]) == \"\".join(target_tokens[k]), f\"Ref and target tokens are not aligned!\"\n",
        "\n",
        "        # t2 = time.time(); print(\"Align strings costs\", t2-t1)\n",
        "\n",
        "        # Loss start at the second token\n",
        "        ref_tokens[k][1] = ref_tokens[k][0] + ref_tokens[k][1]\n",
        "        target_tokens[k][1] = target_tokens[k][0] + target_tokens[k][1]\n",
        "        ref_tokens[k].pop(0)\n",
        "        target_tokens[k].pop(0)\n",
        "\n",
        "        aligned_loss: list[float] = []\n",
        "        i = 0; j = 0\n",
        "        tmp_ref_str = \"\"\n",
        "        tmp_target_str = \"\"\n",
        "        tmp_target_str_start = 0\n",
        "        ref_loss_accum = 0.0\n",
        "        while i < len(ref_tokens[k]) or j < len(target_tokens[k]):\n",
        "            if tmp_ref_str == \"\" and tmp_target_str == \"\":\n",
        "                if i >= len(ref_tokens[k]) or j >= len(target_tokens[k]):\n",
        "                    break\n",
        "                tmp_ref_str = ref_tokens[k][i]\n",
        "                tmp_target_str = target_tokens[k][j]\n",
        "                tmp_target_str_start = j\n",
        "                ref_loss_accum = ref_loss[k][i]\n",
        "                i += 1\n",
        "                j += 1\n",
        "            if len(tmp_ref_str) < len(tmp_target_str):\n",
        "                ref_loss_accum += ref_loss[k][i]\n",
        "                tmp_ref_str += ref_tokens[k][i]\n",
        "                i += 1\n",
        "            if len(tmp_ref_str) > len(tmp_target_str):\n",
        "                tmp_target_str += target_tokens[k][j]\n",
        "                j += 1\n",
        "            if tmp_ref_str == tmp_target_str:\n",
        "                for _ in range(j-tmp_target_str_start):\n",
        "                    aligned_loss.append(ref_loss_accum / (j-tmp_target_str_start))\n",
        "                # aligned_loss += [ref_loss_accum/(j-tmp_target_str_start)]*(j-tmp_target_str_start)\n",
        "                tmp_ref_str = \"\"\n",
        "                tmp_target_str = \"\"\n",
        "                ref_loss_accum = 0.0\n",
        "        if j < len(target_tokens[k]):\n",
        "            for _ in range(len(target_tokens[k]) - j):\n",
        "                aligned_loss.append(0.0)\n",
        "            # aligned_loss += [0.0] * (len(target_tokens[k]) - j)\n",
        "        # assert len(aligned_loss) == len(target_tokens[k])\n",
        "        aligned_losses.append(aligned_loss)\n",
        "\n",
        "        # t3 = time.time(); print(\"Align tokens costs\", t3-t2)\n",
        "\n",
        "        # print('Total Operations', total_operations)\n",
        "\n",
        "    return aligned_losses"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers evaluate accelerate datasets==3.1.0 gcsfs==2024.9.0 fsspec==2024.6.1"
      ],
      "metadata": {
        "id": "AFQ8npXrdC9E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28275370-e2a0-4963-c801-789acc7c96e0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.1.1)\n",
            "Requirement already satisfied: datasets==3.1.0 in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: gcsfs==2024.9.0 in /usr/local/lib/python3.10/dist-packages (2024.9.0)\n",
            "Requirement already satisfied: fsspec==2024.6.1 in /usr/local/lib/python3.10/dist-packages (2024.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets==3.1.0) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets==3.1.0) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==3.1.0) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets==3.1.0) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==3.1.0) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets==3.1.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets==3.1.0) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets==3.1.0) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets==3.1.0) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==3.1.0) (3.11.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets==3.1.0) (0.26.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets==3.1.0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets==3.1.0) (6.0.2)\n",
            "Requirement already satisfied: decorator>4.1.2 in /usr/local/lib/python3.10/dist-packages (from gcsfs==2024.9.0) (4.4.2)\n",
            "Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.10/dist-packages (from gcsfs==2024.9.0) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.10/dist-packages (from gcsfs==2024.9.0) (1.2.1)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.10/dist-packages (from gcsfs==2024.9.0) (2.8.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.4.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.1.0) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.1.0) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.1.0) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.1.0) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.1.0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.1.0) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.1.0) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.1.0) (1.18.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.2->gcsfs==2024.9.0) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.2->gcsfs==2024.9.0) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.2->gcsfs==2024.9.0) (4.9)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets==3.1.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets==3.1.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets==3.1.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets==3.1.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets==3.1.0) (2024.8.30)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.0.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib->gcsfs==2024.9.0) (1.3.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->gcsfs==2024.9.0) (2.19.2)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->gcsfs==2024.9.0) (2.4.1)\n",
            "Requirement already satisfied: google-resumable-media>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->gcsfs==2024.9.0) (2.7.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==3.1.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==3.1.0) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==3.1.0) (2024.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage->gcsfs==2024.9.0) (1.66.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage->gcsfs==2024.9.0) (4.25.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage->gcsfs==2024.9.0) (1.25.0)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media>=2.3.2->google-cloud-storage->gcsfs==2024.9.0) (1.6.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs==2024.9.0) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==3.1.0) (1.17.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs==2024.9.0) (3.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "\n",
        "def parse_args():\n",
        "    args = argparse.ArgumentParser()\n",
        "\n",
        "    group = args.add_argument_group(\"Model and Data\")\n",
        "    # group.add_argument(\"--datasets\", type=str, default=\"open-web-math/open-web-math\")\n",
        "    group.add_argument(\"--datasets\", type=str, default=\"brando/small-open-web-math-dataset-v2\")\n",
        "    group.add_argument(\"--model_path\", type=str, default=\"TinyLlama/TinyLlama_v1.1\")\n",
        "    group.add_argument(\"--output_dir\", type=str, default=\"ref_model\")\n",
        "    group.add_argument(\"--model_cache_dir\", type=str, default=None)\n",
        "    group.add_argument(\"--data_cache_dir\", type=str, default=None)\n",
        "\n",
        "    group = args.add_argument_group(\"Training\")\n",
        "    group.add_argument(\"--batch_size\", type=int, default=1)\n",
        "    group.add_argument(\"--weight_decay\", type=float, default=1e-2)\n",
        "    group.add_argument(\"--context_length\", type=int, default=2048)\n",
        "    group.add_argument(\"--random_seed\", type=int, default=1234)\n",
        "    group.add_argument(\"--epochs\", type=int, default=1)\n",
        "    group.add_argument(\"--learning_rate\", type=float, default=6e-5)\n",
        "    group.add_argument(\"--eval_steps\", type=int, default=1000)\n",
        "    group.add_argument(\"--gradient_accumulation_steps\", type=int, default=32)\n",
        "    group.add_argument(\"--train_ratio\", type=float, default=0.999)\n",
        "    group.add_argument(\"--save_steps\", type=int, default=100)\n",
        "\n",
        "    group = args.add_argument_group(\"Token Dropping\")\n",
        "    group.add_argument(\"--ref_model_backend\",\n",
        "                       type=str, default=\"hf\", choices=[\"hf\", \"vllm\", \"socket\", \"none\"])\n",
        "    group.add_argument(\"--ref_socket_hosts\",\n",
        "                       type=str, default=\"127.0.0.1\")\n",
        "    group.add_argument(\"--ref_socket_ports\",\n",
        "                       type=str, default=\"65432\")\n",
        "    group.add_argument(\"--vllm_url\",\n",
        "                       type=str, default=\"http://gpu14:8000/v1\")\n",
        "    # group.add_argument(\"--ref_model_path\",\n",
        "    #                     type=str, default=\"microsoft/Phi-3-mini-4k-instruct\")\n",
        "    group.add_argument(\"--ref_model_path\",\n",
        "                    type=str, default=\"DerekChai/TinyLlamaRef\")\n",
        "    group.add_argument(\"--dropping_strategy\",\n",
        "                        type=str, default=\"std\", choices=[\"fixed\", \"dynamic\",\"std\"])\n",
        "    group.add_argument(\"--drop_rate\",\n",
        "                        type=float, default=0.3)\n",
        "    group.add_argument(\"--pre_compute_ref\",\n",
        "                        action=\"store_true\", default=True)\n",
        "\n",
        "    return args.parse_known_args()"
      ],
      "metadata": {
        "id": "tNAeiNJqBPpr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#build data\n",
        "import os\n",
        "import sys\n",
        "import pdb\n",
        "import torch\n",
        "import psutil\n",
        "import argparse\n",
        "\n",
        "\n",
        "from getpass import getpass\n",
        "\n",
        "hf_token = getpass(\"Enter your Hugging Face token:\")\n",
        "os.environ['HF_TOKEN'] = hf_token\n",
        "from huggingface_hub import login\n",
        "login(token=os.environ['HF_TOKEN'])\n",
        "# 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\n",
        "\n",
        "if 'HF_HOME' not in os.environ:\n",
        "  os.environ['HF_HOME'] = os.path.expanduser(\"~/.cache/huggingface\")\n",
        "\n",
        "from datasets import load_dataset, DatasetDict, Dataset, concatenate_datasets\n",
        "\n",
        "\n",
        "\n",
        "def get_cache_dir(args):\n",
        "    # 检查 HF_HOME 环境变量是否存在\n",
        "    hf_home = os.getenv('HF_HOME')\n",
        "    if hf_home is None:\n",
        "        # 如果没有设置 HF_HOME，使用默认路径\n",
        "        hf_home = os.path.expanduser(\"~/.cache/huggingface\")\n",
        "    else:\n",
        "      print(\"hahaha\")\n",
        "    # 构建模型和数据的缓存目录\n",
        "    model_cache_dir = os.path.join(hf_home, \"token_dropping\", args.output_dir)\n",
        "    data_cache_dir = os.path.join(hf_home, \"token_dropping\", \"data\", args.datasets.replace(\",\", \"-\").replace(\"/\", \"-\") + f\"_{args.random_seed}_{args.train_ratio}\")\n",
        "\n",
        "    # 确保目录存在\n",
        "    os.makedirs(model_cache_dir, exist_ok=True)\n",
        "    os.makedirs(data_cache_dir, exist_ok=True)\n",
        "\n",
        "    # 将缓存目录添加到 sys.argv\n",
        "    sys.argv += [\"--model_cache_dir\", model_cache_dir, \"--data_cache_dir\", data_cache_dir]\n",
        "\n",
        "    return model_cache_dir, data_cache_dir\n",
        "# def get_cache_dir(args):\n",
        "#     model_cache_dir = os.path.join(os.environ['HF_HOME'], \"token_dropping\", args.output_dir)\n",
        "#     data_cache_dir = os.path.join(os.environ['HF_HOME'], \"token_dropping\", \"data\", args.datasets.replace(\",\", \"-\").replace(\"/\", \"-\") + f\"_{args.random_seed}_{args.train_ratio}\")\n",
        "#     os.makedirs(model_cache_dir, exist_ok=True)\n",
        "#     os.makedirs(data_cache_dir, exist_ok=True)\n",
        "#     sys.argv += [\"--model_cache_dir\", model_cache_dir, \"--data_cache_dir\", data_cache_dir]\n",
        "#     return model_cache_dir, data_cache_dir\n",
        "\n",
        "\n",
        "def build_prompt(element, prompt, entries, entry_func):\n",
        "    \"\"\"\n",
        "    Build prompt for the given element.\n",
        "    \"\"\"\n",
        "    element[\"prompt\"] = [\n",
        "        prompt.format(**entry_func({entry: element[entry][i] for entry in entries}))\n",
        "        for i in range(len(element[entries[0]]))\n",
        "    ]\n",
        "    return element\n",
        "\n",
        "\n",
        "def build_instruct(\n",
        "        ds: Dataset, cache_path, prompt=\"Question: {instruction}\\n\\nAnswer: {response}\",\n",
        "        entries=[\"instruction\", \"response\"], entry_func=lambda x:x) -> Dataset:\n",
        "    \"\"\"\n",
        "    Build instruction prompt for the given dataset.\n",
        "    Another template:\n",
        "    prompt_template = \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n ### Instruction:\\n{instruction}\\n\\n ### Response: Let's think step by step. {response}\"\n",
        "    \"\"\"\n",
        "    return ds.map(\n",
        "        build_prompt,\n",
        "        fn_kwargs={\"prompt\": prompt, \"entries\": entries, \"entry_func\": entry_func},\n",
        "        num_proc=psutil.cpu_count(),\n",
        "        batched=True, batch_size=1000,\n",
        "        load_from_cache_file=True, cache_file_name=cache_path,\n",
        "        remove_columns=entries\n",
        "    ).rename_column(\"prompt\", \"text\")\n",
        "\n",
        "\n",
        "def build_pretrain_data(datasets: list[str], train_val_split: list[float], seed=None) -> Dataset:\n",
        "    \"\"\"\n",
        "    (1) High-quality math data:\n",
        "        math-ai/AutoMathText\n",
        "        meta-math/MetaMathQA\n",
        "        math-ai/StackMathQA\n",
        "        microsoft/orca-math-word-problems-200k\n",
        "\n",
        "    (2) Instruction Tuning / DPO:\n",
        "        TIGER-Lab/MathInstruct\n",
        "        xinlai/Math-Step-DPO-10K\n",
        "\n",
        "    (3) Open web math data:\n",
        "        open-web-math/open-web-math\n",
        "    \"\"\"\n",
        "    ds_mix = []\n",
        "\n",
        "    for dataset in datasets:\n",
        "        # Create cache directory\n",
        "        dataset_cache_dir = os.path.join(os.environ['HF_HOME'], \"proc_data\", dataset.replace(\"/\", \"_\"))\n",
        "        os.makedirs(dataset_cache_dir, exist_ok=True)\n",
        "        # Load and process dataset\n",
        "        if dataset == \"math-ai/AutoMathText\":\n",
        "            ds = concatenate_datasets([\n",
        "                load_dataset(dataset, \"web-0.50-to-1.00\", split=\"train\").remove_columns([\"url\", \"date\", \"meta\"]),\n",
        "                load_dataset(dataset, \"arxiv-0.50-to-1.00\", split=\"train\").remove_columns([\"url\", \"title\", \"abstract\", \"meta\"])\n",
        "            ])\n",
        "        elif dataset == \"meta-math/MetaMathQA\": #\n",
        "            ds = load_dataset(dataset, split=\"train\").remove_columns([\"type\", \"original_question\"]).rename_columns({\"query\": \"instruction\"})\n",
        "            ds = build_instruct(ds, os.path.join(dataset_cache_dir, \"prompt.cache\"))\n",
        "        elif dataset == \"math-ai/StackMathQA\":\n",
        "            ds = load_dataset(dataset, \"stackmathqa1600k\", split=\"train\").remove_columns([\"meta\"]).rename_columns({\"Q\": \"instruction\", \"A\": \"response\"})\n",
        "            ds = build_instruct(ds, os.path.join(dataset_cache_dir, \"prompt.cache\"))\n",
        "        elif dataset == \"microsoft/orca-math-word-problems-200k\": #\n",
        "            ds = load_dataset(dataset, split=\"train\").rename_columns({\"question\": \"instruction\", \"answer\": \"response\"})\n",
        "            ds = build_instruct(ds, os.path.join(dataset_cache_dir, \"prompt.cache\"))\n",
        "        elif dataset == \"TIGER-Lab/MathInstruct\": #\n",
        "            ds = load_dataset(dataset, split=\"train\").remove_columns([\"source\"]).rename_column(\"output\", \"response\")\n",
        "            ds = build_instruct(ds, os.path.join(dataset_cache_dir, \"prompt.cache\"))\n",
        "        elif dataset == \"open-web-math/open-web-math\":\n",
        "            ds = load_dataset(dataset, split=\"train\").remove_columns([\"url\", \"date\", \"metadata\"])\n",
        "        elif dataset == \"brando/small-open-web-math-dataset-v2\":\n",
        "            ds = load_dataset(dataset, split=\"train\")\n",
        "        elif dataset == \"hkust-nlp/dart-math-uniform\":\n",
        "            ds = load_dataset(dataset, split=\"train\").rename_column(\"query\", \"instruction\")\n",
        "            ds = build_instruct(ds, os.path.join(dataset_cache_dir, \"prompt.cache\"))\n",
        "        elif dataset == \"Vivacem/MMIQC\":\n",
        "            ds = load_dataset(dataset, split=\"train\").remove_columns([\"source\"]).rename_column(\"output\", \"response\")\n",
        "            ds = build_instruct(ds, os.path.join(dataset_cache_dir, \"prompt.cache\"))\n",
        "        elif dataset == \"hkust-nlp/dart-math-hard\": #\n",
        "            ds = load_dataset(dataset, split=\"train\").rename_column(\"query\", \"instruction\")\n",
        "            ds = build_instruct(ds, os.path.join(dataset_cache_dir, \"prompt.cache\"))\n",
        "        elif dataset == \"allenai/math_qa\":\n",
        "            ds = concatenate_datasets([\n",
        "                load_dataset(dataset, split=\"train\", trust_remote_code=True),\n",
        "                load_dataset(dataset, split=\"validation\", trust_remote_code=True),\n",
        "                load_dataset(dataset, split=\"test\", trust_remote_code=True)\n",
        "            ]).remove_columns([\"annotated_formula\", \"category\", \"correct\", \"linear_formula\"])\n",
        "            def entry_func(x):\n",
        "                x['Rationale'] = x['Rationale'].strip(\"\\\"\")\n",
        "                return x\n",
        "            ds = build_instruct(\n",
        "                ds, os.path.join(dataset_cache_dir, \"prompt.cache\"),\n",
        "                prompt=\"Question: {Problem} What of the following is the right choice? Explain your answer. {options}. Answer: {Rationale}\",\n",
        "                entries=[\"Problem\", \"options\", \"Rationale\"], entry_func=entry_func\n",
        "            )\n",
        "        elif dataset == \"lighteval/MATH\":\n",
        "            ds = concatenate_datasets([\n",
        "                load_dataset(dataset, split=\"train\", trust_remote_code=True),\n",
        "                load_dataset(dataset, split=\"test\", trust_remote_code=True)\n",
        "            ]).remove_columns([\"level\", \"type\"])\n",
        "            ds = build_instruct(\n",
        "                ds, os.path.join(dataset_cache_dir, \"prompt.cache\"),\n",
        "                prompt=\"Question: {problem} Answer: {solution}\",\n",
        "                entries=[\"problem\", \"solution\"]\n",
        "            )\n",
        "        elif dataset == \"peiyi9979/Math-Shepherd\":\n",
        "            ds = load_dataset(dataset, split=\"train\").remove_columns([\"input\", \"task\"])\n",
        "            def entry_func(x):\n",
        "                x['label'] = x['label'].replace(\"+\\n\", \"\").replace(\"-\\n\", \"\").strip(' -')\n",
        "                return x\n",
        "            ds = build_instruct(\n",
        "                ds, os.path.join(dataset_cache_dir, \"prompt.cache\"),\n",
        "                prompt=\"{label}\", entries=[\"label\"], entry_func=entry_func\n",
        "            )\n",
        "        ds_mix.append(ds)\n",
        "\n",
        "    # Concatenate all datasets\n",
        "    ds_mix: Dataset = concatenate_datasets(ds_mix)\n",
        "\n",
        "    # Shuffle the dataset and split into train and valid\n",
        "    ds_mix = ds_mix.shuffle(seed=seed)\n",
        "    ds_mix_split = DatasetDict({\n",
        "        \"train\": ds_mix.select(range(int(len(ds_mix) * train_val_split[0]))),\n",
        "        \"valid\": ds_mix.select(range(int(len(ds_mix) * train_val_split[0]), len(ds_mix)))\n",
        "    })\n",
        "\n",
        "    print(ds_mix)\n",
        "\n",
        "    print(\"Dataset examples: (train and valid)\")\n",
        "    print(ds_mix_split[\"train\"][0])\n",
        "    print(ds_mix_split[\"valid\"][0])\n",
        "\n",
        "    return ds_mix_split\n",
        "\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "# args = argparse.ArgumentParser()\n",
        "# args.add_argument(\"--datasets\", type=str, default=\"meta-math/MetaMathQA\")\n",
        "# args.add_argument(\"--output-json\", type=str, default=None)\n",
        "# args_parse = args.parse_args()\n",
        "\n",
        "# parser = argparse.ArgumentParser()\n",
        "# parser.add_argument(\"--datasets\", type=str, default=\"meta-math/MetaMathQA\")\n",
        "# parser.add_argument(\"--output-json\", type=str, default=None)\n",
        "# known_args, _ = parser.parse_known_args()\n",
        "# print(f\"Datasets: {known_args.datasets}\")\n",
        "# print(f\"Output JSON: {known_args.output_json}\")\n",
        "\n",
        "\n",
        "#     if args_parse.output_json is None:\n",
        "#         build_pretrain_data(args_parse.datasets.split(\",\"), train_val_split=[0.99, 0.01], seed=None)\n",
        "#     else:\n",
        "#         print(\"Saving Json File to\", args_parse.output_json)\n",
        "#         ds = build_pretrain_data(args_parse.datasets.split(\",\"), train_val_split=[0.99, 0.01], seed=None)\n",
        "#         concatenate_datasets([ds['train'], ds['valid']]).to_json(args_parse.output_json, lines=True)\n",
        "# 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"
      ],
      "metadata": {
        "id": "ZH9JsuxYb60H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68f28902-f891-4bfd-fcbb-e426a16d51cb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Hugging Face token:··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
            "WARNING:huggingface_hub._login:Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ref server\n",
        "import socket\n",
        "import argparse\n",
        "import torch\n",
        "import time\n",
        "import pickle\n",
        "import multiprocessing\n",
        "\n",
        "# from model.utils import align_ref_target_tokens, tokenized_prompts, causal_modeling_loss\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoConfig\n",
        "\n",
        "def init_socket(args):\n",
        "    hosts = args.ref_socket_hosts.split(\",\")\n",
        "    ports = args.ref_socket_ports.split(\",\")\n",
        "    assert len(hosts) == 1 or len(hosts) == len(ports), \"Invalid hosts:ports configuration.\"\n",
        "    if torch.distributed.is_initialized():\n",
        "        selected_host = torch.distributed.get_rank() % len(ports)\n",
        "        if len(hosts) > 1:\n",
        "            host = hosts[selected_host]\n",
        "        else:\n",
        "            host = hosts[0]\n",
        "        port = int(ports[selected_host])\n",
        "    else:\n",
        "        host = hosts[0]\n",
        "        port = int(ports[0])\n",
        "    print(\"Connecting to\", host, port)\n",
        "    client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "    client_socket.connect((host, port))\n",
        "    # Create a message queue\n",
        "    recv_queue = multiprocessing.Queue()\n",
        "    send_queue = multiprocessing.Queue()\n",
        "    # Start a process to handle async receiving of data\n",
        "    receive_process = multiprocessing.Process(target=init_recv_queue, args=(client_socket, recv_queue))\n",
        "    receive_process.daemon = True\n",
        "    receive_process.start()\n",
        "    # Start a process to handle async sending of data\n",
        "    send_process = multiprocessing.Process(target=init_send_queue, args=(client_socket, send_queue))\n",
        "    send_process.daemon = True\n",
        "    send_process.start()\n",
        "    return recv_queue, send_queue\n",
        "\n",
        "def init_recv_queue(socket, queue):\n",
        "    while True:\n",
        "        try:\n",
        "            data = receive_all(socket)\n",
        "            queue.put(pickle.loads(data))\n",
        "        except Exception as e:\n",
        "            print(f\"Error receiving data: {e}\")\n",
        "            break\n",
        "\n",
        "def init_send_queue(socket, queue):\n",
        "    while True:\n",
        "        try:\n",
        "            data = queue.get()\n",
        "            send_all(socket, pickle.dumps(data))\n",
        "        except Exception as e:\n",
        "            print(f\"Error sending data: {e}\")\n",
        "            break\n",
        "\n",
        "def receive_all(client_socket):\n",
        "    \"\"\"Receives all data from the client.\"\"\"\n",
        "    # First, receive the size of the data\n",
        "    data_size = int.from_bytes(client_socket.recv(4), byteorder='big')\n",
        "    data = b\"\"\n",
        "    while len(data) < data_size:\n",
        "        part = client_socket.recv(min(4096, data_size - len(data)))\n",
        "        data += part\n",
        "    return data\n",
        "\n",
        "def send_all(client_socket, data):\n",
        "    \"\"\"Sends all data to the client.\"\"\"\n",
        "    # First, send the size of the data\n",
        "    data_size = len(data)\n",
        "    client_socket.sendall(data_size.to_bytes(4, byteorder='big'))\n",
        "    # Then, send all the data\n",
        "    client_socket.sendall(data)\n",
        "\n",
        "@torch.inference_mode()\n",
        "def obtain_ref_loss(model, tokenizer, messages, target_tokenizer=None, tokenize_args={}, return_pickle=True):\n",
        "    target_input_ids = messages\n",
        "    messages = target_tokenizer.batch_decode(messages)\n",
        "\n",
        "    inputs = tokenizer(messages, return_tensors=\"pt\", padding=True, **tokenize_args).to('cuda')\n",
        "    # t1 = time.time()\n",
        "    # Forward pass through the model\n",
        "    outputs = model(**inputs)\n",
        "    # Calculate the loss for the batch\n",
        "    loss = causal_modeling_loss(logits=outputs.logits, inputs=inputs.input_ids, attention_mask=inputs.attention_mask)\n",
        "\n",
        "    size_of_token = [sum(inputs.attention_mask[e].detach().cpu().tolist()) for e in range(len(inputs.attention_mask))]\n",
        "    loss_list = loss.detach().cpu().tolist()\n",
        "    loss_list = [loss_list[e][-(size_of_token[e]-1):] for e in range(len(loss_list))]\n",
        "    ref_input_ids = inputs.input_ids.detach().cpu().tolist()\n",
        "    ref_input_ids = [ref_input_ids[e][-(size_of_token[e]-1):] for e in range(len(ref_input_ids))]\n",
        "\n",
        "    # Align the loss using the target tokenizer\n",
        "    if target_tokenizer is not None:\n",
        "        ref_tokens = tokenized_prompts(tokenizer, input_ids=ref_input_ids)\n",
        "        target_tokens = tokenized_prompts(target_tokenizer, input_ids=target_input_ids)\n",
        "        loss_list = align_ref_target_tokens(\n",
        "            ref_tokens=ref_tokens,\n",
        "            target_tokens=target_tokens,\n",
        "            ref_loss=loss_list\n",
        "        )\n",
        "    # Serialize the loss object to a byte stream\n",
        "    if return_pickle:\n",
        "        response = pickle.dumps({\n",
        "            \"loss\": loss_list\n",
        "        })\n",
        "        return response\n",
        "    else:\n",
        "        return loss_list\n",
        "\n",
        "\n",
        "def handle_client(client_id, client_socket, queue):\n",
        "    \"\"\"Handles communication with a single client.\"\"\"\n",
        "    try:\n",
        "        while True:\n",
        "            message = receive_all(client_socket)\n",
        "            if not message:\n",
        "                break\n",
        "            messages = pickle.loads(message)\n",
        "            queue.put((client_id, messages))\n",
        "    except ConnectionResetError:\n",
        "        print(\"Client disconnected abruptly.\")\n",
        "    finally:\n",
        "        client_socket.close()\n",
        "\n",
        "\n",
        "def start_server(host, port, model_name, target_tokenizer=None, context_length=2048):\n",
        "    # Load the model and tokenizer\n",
        "    config = AutoConfig.from_pretrained(model_name)\n",
        "    num_gpus = torch.cuda.device_count()\n",
        "    num_first_state_layers = 1\n",
        "    num_last_state_layers = 9\n",
        "    num_middle_state_layers = (config.num_hidden_layers - num_first_state_layers - num_last_state_layers) // (num_gpus-2)\n",
        "    layer_split = [num_first_state_layers] + [num_middle_state_layers] * (num_gpus-2) + [num_last_state_layers]\n",
        "\n",
        "    device_map = {\n",
        "        'model.embed_tokens': 0,\n",
        "        'lm_head': 0,\n",
        "        'model.norm': num_gpus-1,\n",
        "        'model.rotary_emb': num_gpus-1,\n",
        "    }\n",
        "\n",
        "    layer_counter = 0\n",
        "    for i in range(num_gpus):\n",
        "        for j in range(layer_split[i]):\n",
        "            device_map[f'model.layers.{layer_counter}'] = i\n",
        "            layer_counter += 1\n",
        "\n",
        "    # Load the model and tokenizer from Hugging Face\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name, torch_dtype=torch.bfloat16,\n",
        "        # device_map=device_map,\n",
        "    ).to('cuda')\n",
        "    model.eval()\n",
        "\n",
        "    if target_tokenizer is not None and target_tokenizer != model_name:\n",
        "        target_tokenizer = AutoTokenizer.from_pretrained(target_tokenizer)\n",
        "    else:\n",
        "        target_tokenizer = None\n",
        "\n",
        "    \"\"\"Starts the server and listens for incoming client connections.\"\"\"\n",
        "    server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "    server_socket.bind((host, port))\n",
        "    server_socket.listen(5)\n",
        "    print(f\"Server listening on {host}:{port}\")\n",
        "\n",
        "    client_sockets = []\n",
        "    while len(client_sockets) < args.num_connects:\n",
        "        client_socket, addr = server_socket.accept()\n",
        "        print(f\"Accepted connection from {addr}\")\n",
        "        client_sockets.append(client_socket)\n",
        "\n",
        "    # Start process for each client connection\n",
        "    recv_q = multiprocessing.Queue()\n",
        "    for c_id in range(len(client_sockets)):\n",
        "        client_process = multiprocessing.Process(\n",
        "            target=handle_client, args=(c_id, client_sockets[c_id], recv_q)\n",
        "        )\n",
        "        client_process.daemon = True\n",
        "        client_process.start()\n",
        "\n",
        "    tokenize_args = {\"truncation\": True, \"max_length\": context_length, \"return_overflowing_tokens\": False, \"return_length\": False, \"padding_side\": \"left\"}\n",
        "\n",
        "    try:\n",
        "        sample_counter = 0\n",
        "        start = time.time()\n",
        "        while True:\n",
        "            # Wait for a message from the queue\n",
        "            client_id, messages = recv_q.get()\n",
        "            # Process the message and obtain the loss\n",
        "            response = obtain_ref_loss(model, tokenizer, messages, target_tokenizer, tokenize_args)\n",
        "            # print(\"Server processes message\", client_id, [len(e) for e in messages], \"Costs\", time.time()-st)\n",
        "            # Send the result back to the corresponding client\n",
        "            send_all(client_sockets[client_id], response)\n",
        "            sample_counter += 1\n",
        "            print(f\"\\rServer processes {(sample_counter / (time.time() - start)):.2f} samples/second\", flush=True, end=\"\")\n",
        "    except Exception as e:\n",
        "        print(\"Server shutting down.\", e)\n",
        "    finally:\n",
        "        server_socket.close()\n",
        "\n",
        "\n",
        "# def parse_args():\n",
        "#     parser = argparse.ArgumentParser(description=\"Start a server for handling client requests.\")\n",
        "#     parser.add_argument('--host', type=str, default='0.0.0.0', help='Host IP address')\n",
        "#     parser.add_argument('--port', type=int, default=65432, help='Host port number')\n",
        "#     parser.add_argument('--num_connects', type=int, default=4, help='Number of connections to accept')\n",
        "#     parser.add_argument('--model_name', type=str, default='microsoft/Phi-3-mini-4k-instruct', help='Model name to load')\n",
        "#     parser.add_argument('--target_tokenizer', type=str, default=None, help='Target tokenizer to be aligned')\n",
        "#     parser.add_argument('--context_length', type=int, default=2048, help='Maximum context length')\n",
        "#     return parser.parse_known_args()\n",
        "\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "# known_args, _ = parse_args()\n",
        "    # args = parse_args()\n",
        "# start_server(host=known_args.host, port=known_args.port, model_name=known_args.model_name, target_tokenizer=known_args.target_tokenizer, context_length=known_args.context_length)"
      ],
      "metadata": {
        "id": "Fa6swgRRclU1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pdb\n",
        "# import time\n",
        "# import numpy as np\n",
        "\n",
        "# from transformers import AutoTokenizer\n",
        "\n",
        "# # Load the first tokenizer\n",
        "# # tokenizer1 = AutoTokenizer.from_pretrained('meta-llama/Llama-3.2-1B')\n",
        "# tokenizer1 = AutoTokenizer.from_pretrained('Qwen/Qwen2.5-1.5B-Instruct')\n",
        "\n",
        "# # Load the second tokenizer\n",
        "# tokenizer2 = AutoTokenizer.from_pretrained('TinyLlama/TinyLlama_v1.1')\n",
        "\n",
        "# tokenizer1.add_bos_token = False\n",
        "# tokenizer2.add_bos_token = False\n",
        "\n",
        "# data = build_pretrain_data(\n",
        "#     datasets=['open-web-math/open-web-math'],\n",
        "#     train_val_split=[0.8, 0.2],\n",
        "#     seed=1234\n",
        "# )['train']\n",
        "\n",
        "# print(data)\n",
        "\n",
        "# def get_mismatch(a, b):\n",
        "#     i = 0\n",
        "#     while i<len(a) and i<len(b) and a[i] == b[i]:\n",
        "#         i += 1\n",
        "#     return i\n",
        "\n",
        "# Example usage\n",
        "# for i, sample in enumerate(data):\n",
        "\n",
        "    # text = sample[\"text\"]\n",
        "\n",
        "    # tokens2 = tokenizer2(text, truncation=True, max_length=2048)\n",
        "    # decoded_text2 = tokenizer2.decode(tokens2['input_ids']).strip(\"<s> \")\n",
        "\n",
        "    # # Tokenize the text using both tokenizers\n",
        "    # tokens1 = tokenizer1(decoded_text2)\n",
        "    # decoded_text1 = tokenizer1.decode(tokens1['input_ids']).replace(\"<|begin_of_text|>\", \"\")\n",
        "\n",
        "    # print(f\"#\" * 30)\n",
        "    # print(f\"Sample {i} Size {len(decoded_text2)}\")\n",
        "\n",
        "    # start = time.time()\n",
        "    # ref_tokens = [[tokenizer1.decode(e).strip(\" \") for e in tokens1['input_ids']]]\n",
        "    # target_tokens = [[tokenizer2.decode(e).strip(\" \") for e in tokens2['input_ids']]]\n",
        "    # ref_loss = [[1.0] * (len(tokens1['input_ids']) - 1)]\n",
        "    # align_ref_target_tokens(\n",
        "    #     ref_tokens=ref_tokens, # [1:]\n",
        "    #     target_tokens=target_tokens,\n",
        "    #     ref_loss=ref_loss\n",
        "    # )\n",
        "    # end = time.time()\n",
        "    # print(\"Totoal Costs\", end - start)\n",
        "\n",
        "    # if end - start > 0.1:\n",
        "    #     pdb.set_trace()"
      ],
      "metadata": {
        "id": "8ml4T1qy3HZA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pdb\n",
        "import heapq\n",
        "import torch\n",
        "import copy\n",
        "import socket\n",
        "import time\n",
        "import psutil\n",
        "import pickle\n",
        "import functools\n",
        "import datetime\n",
        "import numpy as np\n",
        "import torch.distributed\n",
        "import torch.multiprocessing as mp\n",
        "\n",
        "from tqdm import tqdm\n",
        "from accelerate import Accelerator\n",
        "from accelerate.utils import LoggerType\n",
        "from torch.optim import AdamW,SGD\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM, GPT2Tokenizer, GPT2LMHeadModel\n",
        "from transformers import get_scheduler, LlamaModel, Qwen2Model, PreTrainedTokenizer\n",
        "from datasets import load_dataset, DatasetDict, Dataset\n",
        "\n",
        "# from arguments import parge_args\n",
        "# from ref_server import init_socket, obtain_ref_loss\n",
        "# from data.build_data import build_pretrain_data, get_cache_dir\n",
        "# from model.utils import *\n",
        "\n",
        "def initialize():\n",
        "    # mp.set_start_method('spawn')\n",
        "    # args = parge_args()\n",
        "    args, unknown_args = parse_args()\n",
        "    print(\"Known Args:\", args)\n",
        "    print(\"Unknown Args:\", unknown_args)\n",
        "    torch.random.manual_seed(args.random_seed)\n",
        "    if os.environ.get(\"WORLD_SIZE\") is not None:\n",
        "        torch.distributed.init_process_group(\n",
        "            backend=\"nccl\", world_size=int(os.environ[\"WORLD_SIZE\"]),\n",
        "            rank=int(os.environ[\"RANK\"]), timeout=datetime.timedelta(minutes=120)\n",
        "        )\n",
        "    get_cache_dir(args)\n",
        "\n",
        "# def save_model(accelerator, model, tokenizer, model_cache_dir):\n",
        "#     accelerator.wait_for_everyone()\n",
        "#     unwrapped_model = accelerator.unwrap_model(model)\n",
        "#     unwrapped_model.save_pretrained(model_cache_dir, save_function=accelerator.save)\n",
        "#     if accelerator.is_main_process:\n",
        "#         tokenizer.save_pretrained(model_cache_dir)\n",
        "\n",
        "class Trainer:\n",
        "    def __init__(self, model, tokenizer, train_dataset, eval_dataset):\n",
        "        # self.args = parse_args()\n",
        "        self.args, unknown_args = parse_args()\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.optimizer = SGD(\n",
        "            model.parameters(), lr=self.args.learning_rate,\n",
        "            weight_decay=self.args.weight_decay\n",
        "        )\n",
        "        # datasets are already shuffled\n",
        "        torch_train_dataloader = DataLoader(train_dataset, batch_size=self.args.batch_size, collate_fn=collate_fn)\n",
        "        torch_eval_dataloader = DataLoader(eval_dataset, batch_size=self.args.batch_size, collate_fn=collate_fn)\n",
        "\n",
        "        self.accelerator = Accelerator(\n",
        "        mixed_precision='bf16', gradient_accumulation_steps=self.args.gradient_accumulation_steps,\n",
        "        log_with=[LoggerType.WANDB, LoggerType.TENSORBOARD], project_dir=self.args.model_cache_dir\n",
        "        )\n",
        "        self.accelerator.init_trackers(\n",
        "            f\"{self.args.model_path.split('/')[-1]}\", config=vars(self.args))\n",
        "\n",
        "        self.model, self.optimizer, self.train_dataloader, self.eval_dataloader = self.accelerator.prepare(model, self.optimizer, torch_train_dataloader, torch_eval_dataloader)\n",
        "\n",
        "        self.num_training_steps = self.args.epochs * len(self.train_dataloader)\n",
        "        print(\"Num training steps (after // args.gradient_accumulation_steps):\", self.num_training_steps // self.args.gradient_accumulation_steps)\n",
        "\n",
        "        self.step = 0\n",
        "        self.completed_steps = 0\n",
        "        self.accumulated_loss = 0.0\n",
        "\n",
        "        self.lr_scheduler = get_scheduler(\n",
        "            name=\"cosine_with_min_lr\",\n",
        "            optimizer=self.optimizer,\n",
        "            num_warmup_steps=1_000,\n",
        "            num_training_steps=self.num_training_steps // self.args.gradient_accumulation_steps,\n",
        "            scheduler_specific_kwargs={\"min_lr_rate\": 0.1}\n",
        "        )\n",
        "        self.accelerator.register_for_checkpointing(self.lr_scheduler, self)\n",
        "\n",
        "        # if os.path.exists(self.args.model_cache_dir):\n",
        "        #     self.restore_training()\n",
        "\n",
        "    def state_dict(self):\n",
        "        return {\"step\": self.step, \"completed_steps\": self.completed_steps}\n",
        "\n",
        "    def load_state_dict(self, state_dict):\n",
        "        self.step = state_dict[\"step\"]\n",
        "        self.completed_steps = state_dict[\"completed_steps\"]\n",
        "\n",
        "    def train_step(self, batch, ref_loss=None):\n",
        "        self.step += 1\n",
        "        # Forward Pass (micro-batch)\n",
        "        logits = self.model(batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"]).logits\n",
        "        # Token Filter Loss\n",
        "        loss = token_filter_loss(\n",
        "            batch[\"input_ids\"], logits,\n",
        "            attention_mask=batch[\"attention_mask\"],\n",
        "            ref_loss=ref_loss,\n",
        "            dropping_strategy=self.args.dropping_strategy,\n",
        "            # drop_rate = 0\n",
        "            drop_rate=self.args.drop_rate\n",
        "        )\n",
        "        self.accumulated_loss += loss.item()\n",
        "        self.accelerator.backward(loss)\n",
        "        if self.step % self.args.gradient_accumulation_steps == 0:\n",
        "            # Apply gradients\n",
        "            self.accelerator.clip_grad_norm_(self.model.parameters(), 1.0)\n",
        "            self.optimizer.step()\n",
        "            self.lr_scheduler.step()\n",
        "            self.optimizer.zero_grad()\n",
        "            self.completed_steps += 1\n",
        "            # Log loss\n",
        "            self.accumulated_loss /= self.args.gradient_accumulation_steps\n",
        "            self.accelerator.print(\n",
        "                {\n",
        "                    \"samples\": self.step * self.args.batch_size,\n",
        "                    \"steps\": self.completed_steps,\n",
        "                    \"loss/train\": self.accumulated_loss,\n",
        "                    \"learning rate\": self.lr_scheduler.get_last_lr()[-1]\n",
        "                }\n",
        "            )\n",
        "            self.accelerator.log({\"train_loss\": self.accumulated_loss, \"learning_rate\": self.lr_scheduler.get_last_lr()[-1]}, step=self.completed_steps)\n",
        "            self.accumulated_loss = 0.0\n",
        "        if (self.step % (self.args.eval_steps * self.args.gradient_accumulation_steps)) == 0:\n",
        "            eval_loss, perplexity = evaluate(self.model, self.eval_dataloader, self.accelerator)\n",
        "            self.accelerator.print({\"loss/eval\": eval_loss, \"perplexity\": perplexity})\n",
        "            self.accelerator.log({\"val_loss\": eval_loss, \"val_perplexity\": perplexity}, step=self.completed_steps)\n",
        "            self.model.train()\n",
        "        if (self.step % (self.args.save_steps * self.args.gradient_accumulation_steps)) == 0:\n",
        "            self.save_model()\n",
        "            self.save_training_states()\n",
        "\n",
        "    def save_model(self):\n",
        "        self.accelerator.wait_for_everyone()\n",
        "        unwrapped_model = self.accelerator.unwrap_model(self.model)\n",
        "        unwrapped_model.save_pretrained(self.args.model_cache_dir, save_function=self.accelerator.save)\n",
        "        if self.accelerator.is_main_process:\n",
        "            self.tokenizer.save_pretrained(self.args.model_cache_dir)\n",
        "\n",
        "    def save_training_states(self):\n",
        "        self.accelerator.save_state(self.args.model_cache_dir)\n",
        "\n",
        "    def restore_training(self):\n",
        "        try:\n",
        "            self.accelerator.load_state(self.args.model_cache_dir)\n",
        "            print(\"Continuing training from step\", self.completed_steps)\n",
        "        except (FileNotFoundError, ValueError, AssertionError) as e:\n",
        "            print(f\"Cannot restore training in {self.args.model_cache_dir}, {e}\")\n",
        "\n",
        "    def end_training(self):\n",
        "        self.save_model()\n",
        "        self.accelerator.wait_for_everyone()\n",
        "        self.accelerator.end_training()\n",
        "\n",
        "    def train(self):\n",
        "        for epoch in range(self.args.epochs):\n",
        "            for step, batch in tqdm(\n",
        "                enumerate(self.train_dataloader, start=1+epoch*len(self.train_dataloader)), total=self.num_training_steps\n",
        "            ):\n",
        "                if step <= self.step:\n",
        "                    continue\n",
        "                self.train_step(batch, ref_loss=batch.get(\"ref_loss\", None))\n",
        "        self.end_training()\n",
        "\n",
        "# def main():\n",
        "initialize()\n",
        "args, unknown_args = parse_args()\n",
        "\n",
        "raw_datasets = build_pretrain_data(\n",
        "    args.datasets.split(\",\"),\n",
        "    train_val_split=[args.train_ratio, 1-args.train_ratio],\n",
        "    seed=args.random_seed\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(args.model_path)\n",
        "\n",
        "if args.ref_model_backend == \"hf\":\n",
        "    ref_model = AutoModelForCausalLM.from_pretrained(\n",
        "        args.ref_model_path, torch_dtype=torch.bfloat16, device_map=\"auto\").eval()\n",
        "    ref_tokenizer = AutoTokenizer.from_pretrained(args.ref_model_path)\n",
        "    # Align the tokenizer\n",
        "    ref_tokenizer.add_bos_token = tokenizer.add_bos_token\n",
        "    if ref_tokenizer.pad_token is None:\n",
        "        ref_tokenizer.pad_token = ref_tokenizer.eos_token\n",
        "    ref_batch_size = 2 # decide base on GPU memory\n",
        "elif args.ref_model_backend == \"vllm\":\n",
        "    from openai import OpenAI\n",
        "    client = OpenAI(api_key=\"EMPTY\", base_url=args.vllm_url)\n",
        "    vllm_model = client.models.list().data[0].id\n",
        "    # Test Request\n",
        "    completion = client.completions.create(\n",
        "        model=vllm_model, prompt=[\"How is the weather today?\"],\n",
        "        echo=True, n=1, max_tokens=1, stream=False, logprobs=1,\n",
        "    )\n",
        "    print([choice.logprobs.token_logprobs[1:-1] for choice in completion.choices])\n",
        "\n",
        "tokenizer_args = {\n",
        "    \"max_length\": args.context_length, \"truncation\": True,\n",
        "    \"return_overflowing_tokens\": False, \"return_length\": False, \"padding_side\": \"left\"\n",
        "}\n",
        "\n",
        "def tokenize(element, args=args):\n",
        "    outputs = tokenizer([e + tokenizer.eos_token for e in element[\"text\"]], **tokenizer_args)\n",
        "    if args.pre_compute_ref:\n",
        "        if args.ref_model_backend == \"hf\":\n",
        "            outputs[\"ref_loss\"] = []\n",
        "            for i in range(0, len(outputs[\"input_ids\"]), ref_batch_size):\n",
        "                outputs[\"ref_loss\"] += obtain_ref_loss(\n",
        "                    model=ref_model, tokenizer=ref_tokenizer,\n",
        "                    target_tokenizer=tokenizer, messages=outputs['input_ids'][i:i+ref_batch_size],\n",
        "                    tokenize_args=tokenizer_args, return_pickle=False\n",
        "                )\n",
        "        else:\n",
        "            raise NotImplementedError(f\"Backend {args.ref_model_backend} is not supported for pre-compute ref loss.\")\n",
        "    return outputs\n",
        "\n",
        "# Tokenize the dataset on Rank 0\n",
        "if torch.distributed.is_initialized() and torch.distributed.get_rank() > 0:\n",
        "    torch.distributed.barrier()\n",
        "tokenized_dataset = raw_datasets.map(\n",
        "    tokenize, remove_columns=raw_datasets[\"train\"].column_names,\n",
        "    num_proc=1 if args.pre_compute_ref else (psutil.cpu_count() // 2),\n",
        "    batched=True, batch_size=200,\n",
        "    load_from_cache_file=True, cache_file_names={k: os.path.join(args.data_cache_dir, f\"{k}_tokens.cache\") for k in raw_datasets.keys()},\n",
        ")\n",
        "if torch.distributed.is_initialized() and torch.distributed.get_rank() == 0:\n",
        "    torch.distributed.barrier()\n",
        "print(tokenized_dataset)\n",
        "\n",
        "# Clear ref model on local device\n",
        "if args.ref_model_backend == \"hf\":\n",
        "    del ref_model\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    # model = AutoModelForCausalLM.from_pretrained(args.model_path)\n",
        "    # model = filtering_llama\n",
        "    # model_size = sum(t.numel() for t in model.parameters())\n",
        "    # print(f\"SFT Parameter size: {model_size/1000**2:.1f}M parameters\")\n",
        "\n",
        "    # trainer = Trainer(model, tokenizer, tokenized_dataset[\"train\"], tokenized_dataset[\"valid\"])\n",
        "\n",
        "    # if args.ref_model_backend == \"none\" or args.pre_compute_ref:\n",
        "    #     trainer.train()\n",
        "    # elif args.ref_model_backend == \"vllm\":\n",
        "    #     for epoch in range(args.epochs):\n",
        "    #         for step, batch in tqdm(\n",
        "    #             enumerate(trainer.train_dataloader, start=1+epoch*(trainer.num_training_steps//args.epochs)), total=trainer.num_training_steps\n",
        "    #         ):\n",
        "    #             if step <= trainer.step:\n",
        "    #                 continue\n",
        "    #             # Request ref model (This is very slow)\n",
        "    #             completion = client.completions.create(\n",
        "    #                 model=vllm_model,\n",
        "    #                 prompt=tokenizer.batch_decode(batch[\"input_ids\"]),\n",
        "    #                 echo=True, n=1, max_tokens=1, stream=False, logprobs=1,\n",
        "    #             )\n",
        "    #             ref_loss = [[-e for e in choice.logprobs.token_logprobs[1:-1]] for choice in completion.choices]\n",
        "    #             trainer.train_step(batch, ref_loss=ref_loss)\n",
        "    #     trainer.end_training()\n",
        "    # elif args.ref_model_backend == \"socket\":\n",
        "    #     recv_queue, send_queue = init_socket(args)\n",
        "    #     bar = tqdm(total=trainer.num_training_steps // args.gradient_accumulation_steps)\n",
        "    #     data_queue = []\n",
        "    #     buffer_size = 4 * args.gradient_accumulation_steps\n",
        "    #     for epoch in range(args.epochs):\n",
        "    #         for step, batch in enumerate(\n",
        "    #             trainer.train_dataloader, start=1+epoch*(trainer.num_training_steps//args.epochs)\n",
        "    #         ):\n",
        "    #             if step <= trainer.step:\n",
        "    #                 continue\n",
        "    #             # enter queue and send request\n",
        "    #             data_queue.append(batch)\n",
        "    #             batch_input_ids = batch[\"input_ids\"].tolist()\n",
        "    #             send_queue.put([batch_input_ids[e][-batch['token_size'][e]:] for e in range(len(batch_input_ids))])\n",
        "    #             # train micro-batch\n",
        "    #             if step % args.gradient_accumulation_steps == 0 and step >= buffer_size:\n",
        "    #                 if step == buffer_size:\n",
        "    #                     time.sleep(10)\n",
        "    #                 for mic_i in range(args.gradient_accumulation_steps):\n",
        "    #                     trainer.train_step(data_queue.pop(0), ref_loss=recv_queue.get()['loss'])\n",
        "    #                 bar.update(1)\n",
        "    #     trainer.end_training()\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "# main()"
      ],
      "metadata": {
        "id": "3ud5VKxj3RT1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "020b8fcd-87a3-47fb-b862-06d487123216"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Repo card metadata block was not found. Setting CardData to empty.\n",
            "WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Known Args: Namespace(datasets='brando/small-open-web-math-dataset-v2', model_path='TinyLlama/TinyLlama_v1.1', output_dir='ref_model', model_cache_dir=None, data_cache_dir=None, batch_size=1, weight_decay=0.01, context_length=2048, random_seed=1234, epochs=1, learning_rate=6e-05, eval_steps=1000, gradient_accumulation_steps=32, train_ratio=0.999, save_steps=100, ref_model_backend='hf', ref_socket_hosts='127.0.0.1', ref_socket_ports='65432', vllm_url='http://gpu14:8000/v1', ref_model_path='DerekChai/TinyLlamaRef', dropping_strategy='std', drop_rate=0.3, pre_compute_ref=True)\n",
            "Unknown Args: ['-f', '/root/.local/share/jupyter/runtime/kernel-9a15afb1-bd31-402f-be02-38c4e67aa9e1.json']\n",
            "hahaha\n",
            "Dataset({\n",
            "    features: ['text'],\n",
            "    num_rows: 10000\n",
            "})\n",
            "Dataset examples: (train and valid)\n",
            "{'text': 'Mathematica Help\\n\\n1. Oct 29, 2006\\n\\nDragonfall\\n\\nI want mathematica to evaluate a certain expression (see attached) assuming that n is an integer. The answer is far from what it produces. Maple produces the right answer but I don\\'t have access to it.\\n\\nThe expression is\\n\\n$$\\\\frac{\\\\int_{-\\\\pi}^{\\\\pi}|\\\\sin(x)|\\\\cos(nx)\\\\dx}{\\\\int_{-\\\\pi}^{\\\\pi}\\\\cos^2(nx)\\\\dx}$$\\n\\nAttached Files:\\n\\n• Picture 1.png\\nFile size:\\n1.3 KB\\nViews:\\n86\\nLast edited: Oct 29, 2006\\n2. Oct 30, 2006\\n\\nStephan Hoyer\\n\\nYou need to put a space between your n and x. Mathematica is treating nx as a single variable, which explains the funky result.\\n\\n3. Oct 30, 2006\\n\\nFredGarvin\\n\\nOne other thing to try...I don\\'t have Mathematica in front of me here at work, but I do remember also reading an article about Mathematica getting into a bit of trouble in some cases when using the sybolic integration sign. If Stephan\\'s tip doesn\\'t help, you may try using \"Integrate\" instead of the symbolic operator.\\n\\n4. Oct 30, 2006\\n\\nUse \\'*\\' everywhere, to avoid possible problems. Doesn\\'t look nice, though, but nevermind.\\n\\n5. Oct 30, 2006\\n\\nDragonfall\\n\\nThe error was the missing *. Thanks for the help.\\n\\n6. Oct 30, 2006\\n\\nYes. But note that, as someone above stated, you can simply use the space bar instead of \\'*\\'. Mathematica will produce a small space between the two object that are multiplied.'}\n",
            "{'text': '### November 27, 2006\\n\\nBoth authors are supported in part by National Science Foundation.\\n<ph f=\"cmbx\">A </ph> <math xmlns=\"http://www.w3.org/1998/Math/MathML\"> <mi>C</mi> <mi>r</mi> </math> <ph f=\"cmmi\"> </ph><ph f=\"cmbx\">Closing Lemma for a Class of Symplectic Diffeomorphisms</ph>\\n\\n### Zhihong Xia & Hua Zhang\\n\\nDepartment of Mathematics, Northwestern University, Evanston, IL 60208 E-mail address : xia@math.northwestern.edu & zhang@math.northwestern.edu\\n• Abstract. We prove a ${C}^{r}$\\xa0 closing lemma for a class of partially hyperbolic symplectic diffeomorphisms. We show that for a generic ${C}^{r}$\\xa0 symplectic diffeomorphism, $r=1,2,\\\\dots ,$\\xa0 , with two dimensional center and close to a product map, the set of all periodic points is dense.\\n\\n1 Introduction and Main Result\\n\\nOne of the fundamental problems in dynamical systems is the so-called ${C}^{r}$\\xa0 closing lemma. The problem goes back to Poincaré in his study of the restricted three body problem. It asks whether periodic points are dense for a typical symplectic or volume preserving diffeomorphism on a compact manifold. Let $M$\\xa0 be a compact manifold, with either a symplectic or a volume form $\\\\omega$\\xa0 . Let ${\\\\text{Diff}}_{\\\\omega }^{r}\\\\left(M\\\\right)$\\xa0 be the set of ${C}^{r}$\\xa0 symplectic or volume-preserving diffeomorphisms on $M$\\xa0 . A set in a topological space is said to be residual if it is the intersection of countably many open and dense subsets of of the topological space. A dynamical property is said to be ${C}^{r}$\\xa0 generic on ${\\\\text{Diff}}_{\\\\omega }^{r}\\\\left(M\\\\right)$\\xa0 if there is a residual set $R$\\xa0 such that the property holds for every $f\\\\in R$\\xa0 . In the class symplectic and volume preserving diffeomorphisms, the closing lemma is the following conjecture:\\nConjecture 1 (Closing Lemma for symplectic and volume-preserving diffeomorphisms).\\nAssume $M$\\xa0 is compact. There exists a residual subset $R\\\\subset {\\\\text{Diff}}_{\\\\omega }^{r}\\\\left(M\\\\right)$\\xa0 such that if $f\\\\in R$\\xa0 , the set of periodic points $P=\\\\left\\\\{x\\\\in M|{f}^{p}\\\\left(x\\\\right)=x,\\\\text{for some integer}p\\\\right\\\\}$\\xa0 is dense in $M$\\xa0 .\\nSmale [12listed the problem as one of the mathematical problems for this century.\\nFor $r=1$\\xa0 , the above conjecture is proved to be true by Pugh [9and later improved to various cases by Pugh & Robinson [10. A different proof was given by Liao [5and Mai [6. For higher smoothness $r>1$\\xa0 , besides the hyperbolic cases (the Anosov closing lemma, for uniformly hyperbolic and non-uniformly hyperbolic diffeomorphisms), there is no non-trivial results. On the other hand, example shows that the local perturbation method used in the proof of the ${C}^{1}$\\xa0 closing lemma no longer works for the smoother case. New and global perturbation methods are required (Gutierrez [2). M. Herman [3has a counter example for the ${C}^{r}$\\xa0 closing lemma with $r$\\xa0 large for symplectic diffeomorphisms where the symplectic form is not exact.\\nIn this paper, we prove a ${C}^{r}$\\xa0 closing lemma for arbitrary positive integer $r$\\xa0 for a class of partially hyperbolic symplectic diffeomorphisms.\\nA diffeomorphism $f:M\\\\to M$\\xa0 is partially hyperbolic if the tangent bundle $TM$\\xa0 admits a $Tf$\\xa0 invariant splitting $TM={E}^{u}\\\\oplus {E}^{c}\\\\oplus {E}^{s}$\\xa0 and there is a Riemannian metric on $M$\\xa0 such that there exist real numbers ${\\\\lambda }_{1}>{\\\\lambda }_{2}>1>{\\\\mu }_{2}>{\\\\mu }_{1}>0$\\xa0 satisfying $m\\\\left(Tf{|}_{{E}^{u}}\\\\right)\\\\ge {\\\\lambda }_{1}>{\\\\lambda }_{2}\\\\ge \\\\parallel Tf{|}_{{E}^{c}}\\\\parallel \\\\ge m\\\\left(Tf{|}_{{E}_{c}}\\\\right)\\\\ge {\\\\mu }_{2}>{\\\\mu }_{1}\\\\ge \\\\parallel Tf{|}_{{E}^{s}}\\\\parallel >0.$\\xa0 Here the co-norm $m\\\\left(A\\\\right)$\\xa0 of a linear operator $A$\\xa0 between two Banach spaces is defined by $m\\\\left(A\\\\right):=in{f}_{\\\\parallel v\\\\parallel =1}\\\\parallel A\\\\left(v\\\\right)\\\\parallel =\\\\parallel {A}^{-1}{\\\\parallel }^{-1}$\\xa0 .\\nTo avoid triviality, we assume at least two of the subbundles are non-zero. Partial hyperbolicity is a ${C}^{1}$\\xa0 open condition, as can be easily verified by it\\'s associated invariant cone fields.\\nWe remark that our definition of partial hyperbolicity here is not the most general one. One can allow the parameters ${\\\\lambda }_{1},{\\\\lambda }_{2},{\\\\mu }_{1},{\\\\mu }_{2}$\\xa0 to depend on each trajectory in general cases. The systems that we are considering satisfy the definition given here.\\nFor symplectic cases, the stable distribution ${E}^{s}$\\xa0 and the unstable distribution ${E}^{u}$\\xa0 have the same dimension. Moreover, one can choose the parameters such that ${\\\\lambda }_{1}={\\\\mu }_{1}^{-1}$\\xa0 and ${\\\\lambda }_{2}={\\\\mu }_{2}^{-1}$\\xa0 .\\nWe are now ready to state our main theorem.\\nTheorem 1.1. Let ${M}_{1}$\\xa0 be a compact symplectic manifold and ${f}_{1}\\\\in {\\\\text{Diff}}_{{\\\\omega }_{1}}^{r}\\\\left({M}_{1}\\\\right)$\\xa0 an Anosov diffeomorphism. Let ${M}_{2}$\\xa0 be a compact symplectic surface (orientable surface) with an area form ${\\\\omega }_{2}$\\xa0 and let ${f}_{2}\\\\in {\\\\text{Diff}}_{{\\\\omega }_{2}}^{r}\\\\left({M}_{2}\\\\right)$\\xa0 be an area preserving diffeomorphism on ${M}_{2}$\\xa0 . Let $\\\\omega ={\\\\omega }_{1}+{\\\\omega }_{2}$\\xa0 be the symplectic form defined on ${M}_{1}×{M}_{2}$\\xa0 . Assume that ${f}_{1}$\\xa0 dominates ${f}_{2}$\\xa0 , i.e., ${f}_{1}×{f}_{2}:{M}_{1}×{M}_{2}\\\\to {M}_{1}×{M}_{2}$\\xa0 is partially hyperbolic with $T{M}_{2}$\\xa0 as its center splitting. Then there exists a neighborhood $U$\\xa0 of ${f}_{1}×{f}_{2}$\\xa0 in ${\\\\text{Diff}}_{\\\\omega }^{r}\\\\left({M}_{1}×{M}_{2}\\\\right)$\\xa0 and a residual subset $R\\\\in U$\\xa0 such that for any $g\\\\in U$\\xa0 , the set of periodic points of $g$\\xa0 is dense in ${M}_{1}×{M}_{2}$\\xa0 .\\nThe proof took advantage of the partial hyperbolicity and a recent result of Xia [15on surface diffeomorphisms.\\n\\n2 Partial Hyperbolicity and Symplectic Structure\\n\\nFor a ${C}^{r}$\\xa0 partially hyperbolic diffeomorphism $f$\\xa0 , the stable and unstable bundles are uniquely integrable and are tangent to foliations ${W}_{f}^{s}$\\xa0 and ${W}_{f}^{u}$\\xa0 with ${C}^{r}$\\xa0 leaves.\\n$f$\\xa0 is dynamically coherent if the distributions ${E}^{c}$\\xa0 , ${E}^{c}\\\\oplus {E}^{s}$\\xa0 and ${E}^{c}\\\\oplus {E}^{u}$\\xa0 are integrable, they integrate to foliations ${W}_{f}^{c}$\\xa0 , ${W}_{f}^{cs}$\\xa0 and ${W}_{f}^{cu}$\\xa0 respectively and ${W}_{f}^{c}$\\xa0 and ${W}_{f}^{s}$\\xa0 sub-foliate ${W}_{f}^{cs}$\\xa0 , ${W}_{f}^{c}$\\xa0 and ${W}_{f}^{u}$\\xa0 sub-foliate ${W}_{f}^{cu}$\\xa0 .\\nWe have the following proposition from Pugh & Shub [11.\\nProposition 2.1. Let $f$\\xa0 be a partially hyperbolic diffeomorphism. If the center foliation ${W}_{f}^{c}$\\xa0 exists and is of class ${C}^{1}$\\xa0 , then $f$\\xa0 is stably dynamically coherent, i.e., any $g$\\xa0 which is ${C}^{1}$\\xa0 sufficiently close to $f$\\xa0 is dynamically coherent.\\nLet $W$\\xa0 be a foliation of a compact smooth manifold $M$\\xa0 whose leaves are ${C}^{r}$\\xa0 immersed submanifolds of dimension $k$\\xa0 . For $x\\\\in M$\\xa0 , we call a set $P\\\\left(x\\\\right)\\\\subset W\\\\left(x\\\\right)$\\xa0 a ${C}^{r}$\\xa0 plaque of $W$\\xa0 at $x$\\xa0 if $P\\\\left(x\\\\right)$\\xa0 is the image of a ${C}^{r}$\\xa0 embedding of the unit ball $B\\\\subset {\\\\mathbb{R}}^{k}$\\xa0 into $W\\\\left(x\\\\right)$\\xa0 . A plaquation $\\\\text{P}$\\xa0 for $W$\\xa0 is a collection of plaques such that every point $x\\\\in M$\\xa0 is contained in a plaque $P\\\\in \\\\text{P}$\\xa0 .\\nLet $f$\\xa0 be a diffeomorphism such that $W$\\xa0 is invariant under $f$\\xa0 . A pseudo orbit $\\\\left\\\\{{x}_{n}{\\\\right\\\\}}_{n\\\\in \\\\mathbb{Z}}$\\xa0 respects $\\\\text{P}$\\xa0 if for each $n$\\xa0 , $f\\\\left({x}_{n}\\\\right)$\\xa0 and ${x}_{n+1}$\\xa0 lie in a common plaque $P\\\\in \\\\text{P}$\\xa0 . $f$\\xa0 is called plaque expansive with respect to $W$\\xa0 if there exists $\\\\epsilon >0$\\xa0 such that if two $\\\\epsilon$\\xa0 -pseudo orbits $\\\\left\\\\{{x}_{n}\\\\right\\\\}$\\xa0 and $\\\\left\\\\{{y}_{n}\\\\right\\\\}$\\xa0 both respect $\\\\text{P}$\\xa0 and $d\\\\left({x}_{n},{y}_{n}\\\\right)<\\\\epsilon$\\xa0 for all $n$\\xa0 , then ${x}_{n}$\\xa0 and ${y}_{n}$\\xa0 lie in a common plaque for all $n$\\xa0 .\\nHirsch, Pugh and Shub [4proved that plaque expansiveness with respect to the center foliation of a partially hyperbolic diffeomorphism is a ${C}^{1}$\\xa0 open property and is satisfied when we have smooth center foliation ${W}^{c}$\\xa0 (Theorem 7.1 and 7.2 in [4).\\nIt is clear that under the condition of our main theorem, $f={f}_{1}×{f}_{2}$\\xa0 is partially hyperbolic with smooth center foliation, so there exists neighborhood $U$\\xa0 of ${f}_{1}×{f}_{2}$\\xa0 in ${\\\\text{Diff}}_{\\\\omega }^{r}\\\\left({M}_{1}×{M}_{2}\\\\right)$\\xa0 such that any $g\\\\in U$\\xa0 is partially hyperbolic, dynamically coherent and plaque expansive with respect to the center foliation ${W}_{g}^{c}$\\xa0 .\\nNiţ icǎ and Török in [13proved the following\\nProposition 2.2. Let $M$\\xa0 be a compact manifold with a smooth volume form $\\\\mu$\\xa0 , if $f\\\\in {\\\\text{Diff}}_{\\\\mu }^{1}\\\\left(M\\\\right)$\\xa0 is partially hyperbolic, dynamically coherent and plaque expansive with respect to the center foliation ${W}_{f}^{c}$\\xa0 , then the periodic center leaves of $f$\\xa0 are dense in $M$\\xa0 .\\nNow we have the following\\nLemma 2.3. Under the condition of our main theorem, there exists neighborhood $U$\\xa0 of ${f}_{1}×{f}_{2}$\\xa0 in ${\\\\text{Diff}}_{\\\\omega }^{r}\\\\left({M}_{1}×{M}_{2}\\\\right)$\\xa0 such that any $g\\\\in U$\\xa0 is partially hyperbolic, dynamically coherent and the periodic center leaves of $g$\\xa0 are dense in ${M}_{1}×{M}_{2}$\\xa0 .\\nThe proof is a simple application of the above results and we only have to note that a symplectic diffeomorphism trivially support an invariant smooth volume form.\\nThe following proposition is also from Niţ icǎ and Török [13.\\nProposition 2.4. For a partially hyperbolic diffeomorphism on a compact manifold $M$\\xa0 with center-stable and center-unstable foliations ${W}^{cs}$\\xa0 and ${W}^{cu}$\\xa0 , we have the following local product structure property:\\nThere exist constants $\\\\epsilon >0$\\xa0 , $\\\\delta >0$\\xa0 and $K>1$\\xa0 such that for any $x,y\\\\in M$\\xa0 with $d\\\\left(x,y\\\\right)<\\\\epsilon$\\xa0 , the following hold, 1) ${W}_{\\\\delta }^{s}\\\\left(x\\\\right)$\\xa0 and ${W}_{\\\\delta }^{cu}\\\\left(y\\\\right)$\\xa0 intersect at a unique point ${z}_{1}$\\xa0 , ${W}_{\\\\delta }^{u}\\\\left(x\\\\right)$\\xa0 and ${W}_{\\\\delta }^{cs}\\\\left(y\\\\right)$\\xa0 intersect at a unique point ${z}_{2}$\\xa0 , and moreover $max\\\\left(d\\\\left(x,{z}_{1}\\\\right),d\\\\left(y,{z}_{1}\\\\right)\\\\right)\\xa0 , $max\\\\left(d\\\\left(x,{z}_{2}\\\\right),d\\\\left(y,{z}_{2}\\\\right)\\\\right)\\xa0 .\\n2) ${W}_{\\\\delta }^{cs}\\\\left(x\\\\right)$\\xa0 and ${W}_{\\\\delta }^{cu}\\\\left(y\\\\right)$\\xa0 intersect transversally, same is true for ${W}_{\\\\delta }^{cs}\\\\left(y\\\\right)$\\xa0 and ${W}_{\\\\delta }^{cu}\\\\left(x\\\\right)$\\xa0 .\\n3) ${W}_{\\\\delta }^{cs}\\\\left(x\\\\right)\\\\cap {W}_{\\\\delta }^{cu}\\\\left(x\\\\right)={W}_{\\\\delta }^{c}\\\\left(x\\\\right)$\\xa0 and ${W}_{\\\\delta }^{cs}\\\\left(y\\\\right)\\\\cap {W}_{\\\\delta }^{cu}\\\\left(y\\\\right)={W}_{\\\\delta }^{c}\\\\left(y\\\\right)$\\xa0 .\\nTheorem 6.1 of [4tells us that $\\\\epsilon$\\xa0 , $\\\\delta$\\xa0 and $K$\\xa0 are lower semi-continuous with respect to the ${C}^{1}$\\xa0 topology on ${\\\\text{Diff}}^{1}\\\\left(M\\\\right)$\\xa0 .\\nWe will need a result for symplectic partially hyperbolic diffeomorphisms.\\nLemma 2.5. Let $f$\\xa0 be a symplectic partially hyperbolic diffeomorphism on a compact symplectic manifold $M$\\xa0 , suppose we have the center foliation ${W}_{f}^{c}$\\xa0 , then center manifolds of $f$\\xa0 are symplectic submanifolds and the restrictions of $f$\\xa0 on invariant center leaves are symplectic diffeomorphisms.\\n$\\\\text{Proof}$\\xa0 . For symplectic partially hyperbolic diffeomorphism $f$\\xa0 , there exist $\\\\lambda >\\\\mu >1$\\xa0 such that $m\\\\left(Tf{|}_{{E}^{u}}\\\\right)\\\\ge \\\\lambda >\\\\tau \\\\ge \\\\parallel Tf{|}_{{E}^{c}}\\\\parallel \\\\ge m\\\\left(Tf{|}_{{E}_{c}}\\\\right)\\\\ge {\\\\tau }^{-1}>{\\\\lambda }^{-1}\\\\ge \\\\parallel Tf{|}_{{E}^{s}}\\\\parallel >0.$\\xa0 Denote by $\\\\omega$\\xa0 the symplectic form on $M$\\xa0 . Let $W\\\\subset M$\\xa0 be a center leaf, we should prove $\\\\left(W,\\\\omega {|}_{W}\\\\right)$\\xa0 is a symplectic manifold, i.e., $\\\\omega {|}_{W}$\\xa0 is a non-degenerate, closed two form on $W$\\xa0 . Closeness is obvious since $\\\\omega$\\xa0 is closed on $M$\\xa0 .\\nSuppose that $\\\\omega {|}_{W}$\\xa0 is degenerate, then there exists $x\\\\in W$\\xa0 and a unit vector $u\\\\in {T}_{x}W$\\xa0 such that for all ${v}_{c}\\\\in {T}_{x}W$\\xa0 , $\\\\omega \\\\left(u,{v}_{c}\\\\right)=0$\\xa0 .\\nWe have the splitting ${T}_{x}M={E}_{x}^{s}\\\\oplus {E}_{x}^{c}\\\\oplus {E}_{x}^{u}$\\xa0 , any $v\\\\in {T}_{x}M$\\xa0 can be written as $v={v}_{s}+{v}_{c}+{v}_{u}$\\xa0 , where ${v}_{s}\\\\in {E}_{x}^{s}$\\xa0 , ${v}_{u}\\\\in {E}_{x}^{u}$\\xa0 and ${v}_{c}\\\\in {E}_{x}^{c}={T}_{x}W$\\xa0 .\\nWe have $\\\\omega \\\\left(u,v\\\\right)=\\\\omega \\\\left(u,{v}_{s}\\\\right)+\\\\omega \\\\left(u,{v}_{c}\\\\right)+\\\\omega \\\\left(u,{v}_{u}\\\\right)$\\xa0 and by the way $u$\\xa0 was chosen, $\\\\omega \\\\left(u,{v}_{c}\\\\right)=0$\\xa0 .\\nThere exists $K>0$\\xa0 such that $|\\\\omega \\\\left({w}^{1},{w}^{2}\\\\right)|\\xa0 for arbitrary pair of unit vectors ${w}^{1},{w}^{2}\\\\in {T}_{x}M$\\xa0 .\\nNow we know $\\\\omega \\\\left(u,{v}_{s}\\\\right)=0$\\xa0 because $|\\\\omega \\\\left(u,{v}_{s}\\\\right)|=|\\\\omega \\\\left(T{f}^{n}\\\\left(u\\\\right),T{f}^{n}\\\\left({v}_{s}\\\\right)|\\\\le \\\\left(\\\\frac{\\\\tau }{\\\\lambda }{\\\\right)}^{n}\\\\parallel {v}_{s}\\\\parallel |\\\\omega \\\\left({u}^{n},{v}_{s}^{n}\\\\right)|\\\\le K\\\\left(\\\\frac{\\\\tau }{\\\\lambda }{\\\\right)}^{n}\\\\parallel {v}_{s}\\\\parallel ⟶0$\\xa0 as $n⟶+\\\\infty$\\xa0 .\\nHere ${u}^{n}=T{f}^{n}\\\\left(u\\\\right)/\\\\parallel T{f}^{n}\\\\left(u\\\\right)\\\\parallel$\\xa0 , ${v}_{s}^{n}=T{f}^{n}\\\\left({v}_{s}\\\\right)/\\\\parallel T{f}^{n}\\\\left({v}_{s}\\\\right)\\\\parallel$\\xa0 .\\nSimilarly, we have $\\\\omega \\\\left(u,{v}_{u}\\\\right)=0$\\xa0 and hence $\\\\omega \\\\left(u,v\\\\right)=0$\\xa0 for any $v\\\\in {T}_{x}M$\\xa0 , this contradicts the fact that $\\\\omega$\\xa0 is non-degenerate on $M$\\xa0 .\\nSo $\\\\left(W,\\\\omega {|}_{W}\\\\right)$\\xa0 is a symplectic submanifold and if $W$\\xa0 is invariant under $f$\\xa0 , $f{|}_{W}$\\xa0 preserves $\\\\omega {|}_{W}$\\xa0 and hence is a symplectic diffeomorphism on $W$\\xa0 .\\n\\n3 Some generic properties for area-preserving diffeomorphisms on surfaces\\n\\nTo prove our main theorem, we need some generic properties for surface diffeomorphisms.\\nLet $S$\\xa0 be a compact surface, denote by ${\\\\text{Diff}}_{\\\\mu }^{r}\\\\left(S\\\\right)$\\xa0 the set of area-preserving ${C}^{r}$\\xa0 diffeomorphisms. For $f\\\\in {\\\\text{Diff}}_{\\\\mu }^{r}\\\\left(S\\\\right)$\\xa0 , denote by $HP\\\\left(f\\\\right)$\\xa0 the set of hyperbolic periodic points of $f$\\xa0 . The following generic property was first proved by Mather [7for maps on two sphere ${S}^{2}$\\xa0 and later generalized to arbitrary compact surfaces by Oliveira [8.\\nProposition 3.1. There is a residual subset $R\\\\in {\\\\text{Diff}}_{\\\\mu }^{r}\\\\left(S\\\\right)$\\xa0 such that if $f\\\\in R$\\xa0 and $p\\\\in HP\\\\left(f\\\\right)$\\xa0 is a hyperbolic periodic point of $f$\\xa0 , then $\\\\overline{{W}_{f}^{s}\\\\left(p\\\\right)}=\\\\overline{{W}_{f}^{u}\\\\left(p\\\\right)}.$\\nWe remark that if $r=1$\\xa0 , the proposition is true for generic symplectic and volume preserving diffeomorphisms on any compact manifolds (cf. Xia [14).\\nThe next Theorem is due to Xia [15, extending a recent result of Franks & Le Calvez [1on two sphere.\\nTheorem 3.2. Let $S$\\xa0 be a compact orientable surface and $\\\\mu$\\xa0 be an area form on $S$\\xa0 . For any positive integer $r$\\xa0 , there is a residual subset $R\\\\in {\\\\text{Diff}}_{\\\\mu }^{r}\\\\left(S\\\\right)$\\xa0 such that if $f\\\\in R$\\xa0 , then both the sets ${\\\\cup }_{p\\\\in HP\\\\left(f\\\\right)}{W}^{s}\\\\left(p\\\\right)$\\xa0 and ${\\\\cup }_{p\\\\in HP\\\\left(f\\\\right)}{W}^{u}\\\\left(p\\\\right)$\\xa0 are dense in $S$\\xa0 . Moreover, if an open set $U\\\\subset S$\\xa0 contains no periodic point, then there is a hyperbolic periodic point $p\\\\in HP\\\\left(f\\\\right)$\\xa0 such that both the stable and unstable manifold of $p$\\xa0 is dense in $U$\\xa0 .\\nThe proof uses prime end compactification and a rich literature on area preserving surface diffeomorphisms.\\n\\n4 Proof of the Main Theorem\\n\\nOur main perturbation lemma is from Xia [14.\\nLemma 4.1. Let $M$\\xa0 be a compact symplectic manifold and $f\\\\in {\\\\text{Diff}}_{\\\\omega }^{r}\\\\left(M\\\\right)$\\xa0 , there exist ${\\\\epsilon }_{0}>0$\\xa0 and $c>0$\\xa0 such that for any $g\\\\in {\\\\text{Diff}}_{\\\\omega }^{r}\\\\left(M\\\\right)$\\xa0 such that $\\\\parallel f-g{\\\\parallel }_{{C}^{r}}<{\\\\epsilon }_{0}$\\xa0 and any $0<\\\\epsilon \\\\le {\\\\epsilon }_{0}$\\xa0 , $0<\\\\delta \\\\le {\\\\epsilon }_{0}$\\xa0 , if $x,y\\\\in M$\\xa0 and $d\\\\left(x,y\\\\right)\\xa0 , there exists ${g}_{1}\\\\in {\\\\text{Diff}}_{\\\\omega }^{r}\\\\left(M\\\\right)$\\xa0 , $\\\\parallel {g}_{1}-g{\\\\parallel }_{{C}^{r}}<\\\\epsilon$\\xa0 satisfies ${g}_{1}{g}^{-1}\\\\left(x\\\\right)=y$\\xa0 , ${g}_{1}\\\\left(z\\\\right)=g\\\\left(z\\\\right)$\\xa0 for all $z/\\\\in {g}^{-1}\\\\left({B}_{\\\\delta }\\\\left(x\\\\right)\\\\right)$\\xa0 , and ${g}_{1}^{-1}\\\\left(z\\\\right)={g}^{-1}\\\\left(z\\\\right)$\\xa0 for all $z/\\\\in {B}_{\\\\delta }\\\\left(x\\\\right)$\\xa0 .\\nNow we are ready to prove the main theorem.\\n$\\\\text{Proof}$\\xa0 . By Lemma 2.3, there exists a neighborhood $U$\\xa0 of ${f}_{1}×{f}_{2}$\\xa0 in ${\\\\text{Diff}}_{\\\\omega }^{r}\\\\left({M}_{1}×{M}_{2}\\\\right)$\\xa0 such that any $g\\\\in U$\\xa0 is partially hyperbolic, dynamically coherent and the periodic center leaves of $g$\\xa0 are dense in ${M}_{1}×{M}_{2}$\\xa0 .\\nNow for any fixed $g\\\\in U$\\xa0 , suppose there is a periodic point free open set $V\\\\subset {M}_{1}×{M}_{2}$\\xa0 , we show that by an arbitrarily small perturbation, we can create a periodic point in $V$\\xa0 . It is clear that the main theorem will follow.\\nSince periodic center leaves of $g$\\xa0 are dense, by Proposition 2.4, we can find two periodic center leaves ${W}_{1}$\\xa0 and ${W}_{2}$\\xa0 which are sufficiently close such that there exist ${x}_{1},{y}_{1}\\\\in {W}_{1}\\\\cap V$\\xa0 , ${x}_{2},{y}_{2}\\\\in {W}_{2}\\\\cap V$\\xa0 with $z={W}_{\\\\delta }^{u}\\\\left({x}_{1}\\\\right)\\\\cap {W}_{\\\\delta }^{s}\\\\left({x}_{2}\\\\right)\\\\in V$\\xa0 , $w={W}_{\\\\delta }^{s}\\\\left({y}_{1}\\\\right)\\\\cap {W}_{\\\\delta }^{u}\\\\left({y}_{2}\\\\right)\\\\in V$\\xa0 . ${W}_{1}$\\xa0 and ${W}_{2}$\\xa0 are compact surfaces.\\nBy taking certain power of $g$\\xa0 we may assume that ${W}_{1}$\\xa0 and ${W}_{2}$\\xa0 are invariant under $g$\\xa0 . From Lemma 2.5, ${W}_{1}$\\xa0 and ${W}_{2}$\\xa0 are symplectic submanifolds, ${g}^{1}=g{|}_{{W}_{1}}$\\xa0 and ${g}^{2}=g{|}_{{W}_{2}}$\\xa0 are symplectic diffeomorphisms. By making an arbitrarily small perturbation, we may assume that ${g}^{1}$\\xa0 and ${g}^{2}$\\xa0 satisfy the generic condition in Theorem 3.2. Now ${W}_{i}\\\\cap V$\\xa0 is a periodic point free open set in ${W}_{i}$\\xa0 , we know that there exists ${p}_{i}\\\\in HP\\\\left({g}^{i}\\\\right)$\\xa0 such that ${W}_{{g}^{i}}^{u}\\\\left({p}_{i}\\\\right)$\\xa0 and ${W}_{{g}^{i}}^{s}\\\\left({p}_{i}\\\\right)$\\xa0 are both dense in ${W}_{i}\\\\cap V$\\xa0 , where $i=1,2$\\xa0 .\\nNote that ${p}_{1}$\\xa0 and ${p}_{2}$\\xa0 are hyperbolic periodic points of $g$\\xa0 .\\nWe will show that by an arbitrarily small perturbation, we can change $z$\\xa0 and $w$\\xa0 into heteroclinic points of hyperbolic periodic points ${p}_{1}$\\xa0 and ${p}_{2}$\\xa0 and get a heteroclinic loop. As a result, there will be periodic points in arbitrary neighborhoods of $z$\\xa0 and $w$\\xa0 , including $V$\\xa0 .\\nFor arbitrary $\\\\eta >0$\\xa0 prescribed as the size of the perturbation, take $\\\\epsilon$\\xa0 such that $0<\\\\epsilon \\xa0 , where ${\\\\epsilon }_{0}$\\xa0 is from Lemma 4.1.\\nSince $z\\\\in {W}^{u}\\\\left({W}_{1}\\\\right)$\\xa0 and $z/\\\\in {W}_{1}$\\xa0 , there exists $\\\\alpha$\\xa0 with $0<\\\\alpha <{\\\\epsilon }_{0}$\\xa0 , such that ${B}_{\\\\alpha }\\\\left(z\\\\right)\\\\cap {W}_{1}=\\\\varnothing$\\xa0 and ${g}^{-n}\\\\left(z\\\\right)/\\\\in {B}_{\\\\alpha }\\\\left(z\\\\right)$\\xa0 for all $n\\\\in \\\\mathbb{N}$\\xa0 .\\nFix this $\\\\alpha$\\xa0 , there exists $\\\\beta$\\xa0 with $0<\\\\beta <\\\\alpha$\\xa0 such that for all $\\\\stackrel{~}{z}\\\\in {W}^{u}\\\\left({W}_{1}\\\\right)$\\xa0 with $d\\\\left(\\\\stackrel{~}{z},z\\\\right)<\\\\beta$\\xa0 , we have ${g}^{-n}\\\\left(\\\\stackrel{~}{z}\\\\right)/\\\\in {B}_{\\\\frac{\\\\alpha }{2}}\\\\left(z\\\\right)$\\xa0 for all $n\\\\in \\\\mathbb{N}$\\xa0 .\\nFix this $\\\\beta$\\xa0 , there exists $\\\\gamma$\\xa0 with $0<\\\\gamma \\xa0 , such that for all ${z}_{1}\\\\in {W}^{u}\\\\left({W}_{1}\\\\right)$\\xa0 with $d\\\\left({z}_{1},z\\\\right)<\\\\gamma$\\xa0 , we have ${B}_{\\\\frac{\\\\alpha }{4}}\\\\left({z}_{1}\\\\right)\\\\subset {B}_{\\\\frac{\\\\alpha }{2}}\\\\left(z\\\\right)$\\xa0 and hence ${g}^{-n}\\\\left({z}_{1}\\\\right)/\\\\in {B}_{\\\\frac{\\\\alpha }{4}}\\\\left({z}_{1}\\\\right)$\\xa0 for all $n\\\\in \\\\mathbb{N}$\\xa0 .\\nBy continuity of the unstable foliation, there exists $\\\\nu >0$\\xa0 such that for all ${\\\\stackrel{~}{x}}_{1}\\\\in {W}_{1}$\\xa0 with $d\\\\left({\\\\stackrel{~}{x}}_{1},{x}_{1}\\\\right)<\\\\nu$\\xa0 , there exists ${z}_{1}\\\\in {W}_{g}^{u}\\\\left({\\\\stackrel{~}{x}}_{1}\\\\right)$\\xa0 such that $d\\\\left({z}_{1},z\\\\right)<\\\\gamma$\\xa0 .\\nSince ${W}_{{g}^{1}}^{u}\\\\left({p}_{1}\\\\right)$\\xa0 is dense in ${W}_{1}\\\\cap V$\\xa0 , there exists ${\\\\stackrel{~}{x}}_{1}\\\\in {W}_{{g}^{1}}^{u}\\\\left({p}_{1}\\\\right)$\\xa0 with $d\\\\left({\\\\stackrel{~}{x}}_{1},{x}_{1}\\\\right)<\\\\nu$\\xa0 and hence there is a ${z}_{1}\\\\in {W}_{g}^{u}\\\\left({\\\\stackrel{~}{x}}_{1}\\\\right)$\\xa0 such that $d\\\\left({z}_{1},z\\\\right)<\\\\gamma$\\xa0 .\\nNow we can use the perturbation lemma 4.1 for $g$\\xa0 using the parameters $0<\\\\epsilon <{\\\\epsilon }_{0}$\\xa0 and $0<\\\\delta =\\\\frac{\\\\alpha }{4}<{\\\\epsilon }_{0}$\\xa0 . We have $d\\\\left({z}_{1},z\\\\right)<\\\\gamma \\xa0 , so there exists ${g}_{1}\\\\in {\\\\text{Diff}}_{\\\\omega }^{r}\\\\left({M}_{1}×{M}_{2}\\\\right)$\\xa0 , $\\\\parallel {g}_{1}-g{\\\\parallel }_{{C}^{r}}<\\\\epsilon$\\xa0 satisfies ${g}_{1}{g}^{-1}\\\\left({z}_{1}\\\\right)=z$\\xa0 , ${g}_{1}\\\\left(x\\\\right)=g\\\\left(x\\\\right)$\\xa0 for all $x/\\\\in {g}^{-1}\\\\left({B}_{\\\\delta }\\\\left({z}_{1}\\\\right)\\\\right)$\\xa0 , and ${g}_{1}^{-1}\\\\left(y\\\\right)={g}^{-1}\\\\left(y\\\\right)$\\xa0 for all $y/\\\\in {B}_{\\\\delta }\\\\left({z}_{1}\\\\right)$\\xa0 . We check that after the perturbation, $z\\\\in {\\\\stackrel{~}{W}}_{{g}_{1}}^{u}\\\\left({p}_{1}\\\\right)$\\xa0 , where ${\\\\stackrel{~}{W}}_{{g}_{1}}^{u}\\\\left({p}_{1}\\\\right)$\\xa0 stands for the unstable manifold of the hyperbolic periodic point ${p}_{1}$\\xa0 for ${g}_{1}$\\xa0 , not the leaf of the unstable foliation containing ${p}_{1}$\\xa0 in the partially hyperbolic setting.\\nIt is clear that ${g}_{1}^{-1}\\\\left(z\\\\right)={g}^{-1}\\\\left({z}_{1}\\\\right)$\\xa0 and since ${g}^{-n}\\\\left({z}_{1}\\\\right)/\\\\in {B}_{\\\\delta }\\\\left({z}_{1}\\\\right)$\\xa0 for all $n\\\\in \\\\mathbb{N}$\\xa0 , ${g}_{1}^{-n}\\\\left(z\\\\right)={g}^{-n}\\\\left({z}_{1}\\\\right)$\\xa0 for all $n\\\\in \\\\mathbb{N}$\\xa0 . Moreover, ${g}_{1}^{-n}\\\\left({p}_{1}\\\\right)={g}^{-n}\\\\left({p}_{1}\\\\right)$\\xa0 for all $n\\\\in \\\\mathbb{N}$\\xa0 since ${B}_{\\\\delta }\\\\left({z}_{1}\\\\right)\\\\cap {W}_{1}=\\\\varnothing$\\xa0 .\\nHence we have $d\\\\left({g}_{1}^{-n}\\\\left(z\\\\right),{g}_{1}^{-n}\\\\left({p}_{1}\\\\right)\\\\right)=d\\\\left({g}^{-n}\\\\left({z}_{1}\\\\right),{g}^{-n}\\\\left({p}_{1}\\\\right)\\\\right)$\\xa0 $\\\\le d\\\\left({g}^{-n}\\\\left({z}_{1}\\\\right),{g}^{-n}\\\\left({\\\\stackrel{~}{x}}_{1}\\\\right)\\\\right)+d\\\\left({g}^{-n}\\\\left({\\\\stackrel{~}{x}}_{1}\\\\right),{g}^{-n}\\\\left({p}_{1}\\\\right)\\\\right)⟶0$\\xa0 as $n⟶+\\\\infty$\\xa0 .\\nThis shows $z\\\\in {\\\\stackrel{~}{W}}_{{g}_{1}}^{u}\\\\left({p}_{1}\\\\right)$\\xa0 . The two terms above both go to $0$\\xa0 as $n$\\xa0 goes to $+\\\\infty$\\xa0 since ${z}_{1}\\\\in {W}_{g}^{u}\\\\left({\\\\stackrel{~}{x}}_{1}\\\\right)$\\xa0 and ${\\\\stackrel{~}{x}}_{1}\\\\in {W}_{{g}^{1}}^{u}\\\\left({p}_{1}\\\\right)$\\xa0 .\\nSimilarly we can use a perturbation of size less than $\\\\epsilon$\\xa0 to make $z$\\xa0 on the stable manifold of ${p}_{2}\\\\in {W}_{2}$\\xa0 . Two more of these perturbations will make $w$\\xa0 in the intersection of stable manifold of ${p}_{1}$\\xa0 and unstable manifold of ${p}_{2}$\\xa0 . Finally by a perturbation of size less than $4\\\\epsilon =\\\\eta$\\xa0 , we have the desired heteroclinic loop. This concludes our proof.\\nReferences\\n\\n1. J. Franks and P. Le Calvez. Regions of instability for non-twist maps. Ergodic Theory Dynam. Systems, 23(1):111–141, 2003.\\n2. C. Gutierrez. A counter-example to a ${c}^{2}$\\xa0 closing lemma. Ergodic Theory & Dynamical Systems, 7(4):509–530, 1987.\\n3. M. Herman. Exemples de flots hamiltoniens dont aucune perturbation en topologie ${c}^{\\\\infty }$\\xa0 n\\'a d\\'orbites périodiques sur un ouvert de surfaces d\\'énergie. C.R. Acad. Sci. Paris, t., 312:989–994, 1991.\\n4. M. Hirsch, C. Pugh, and M. Shub. Invariant manifolds, Lect. Notes in Math., volume 583. Springer-Verlag, Berlin-New York, 1977.\\n5. S.T. Liao. An extension of the ${c}^{1}$\\xa0 closing lemma. Acta Sci. Natur. Univ. Pekinensis, 2:1–41, 1979.\\n6. J. Mai. A simpler proof of ${c}^{1}$\\xa0 closing lemma. Scientia Sinica, 10:1021–1031, 1986.\\n7. J. Mather. Topological proofs of some purely topological consequences of carathéodory\\'s theory of prime ends. in Selected Studies. Eds. Th. M. Rassias and G. M. Rassias, pages 225–255, 1982.\\n8. F. Oliveira. On the generic existence of homoclinic points. Ergod. Th. & Dynam. Sys., 7:567–595, 1987.\\n9. C. Pugh. The closing lemma. Amer. J. Math., 89:956–1021, 1967.\\n10. C. Pugh and C. Robinson. The ${c}^{1}$\\xa0 closing lemma, including hamiltonians. Ergod. Th. & Dynam. Sys., 3:261–313, 1983.\\n11. C. Pugh and M. Shub. Stably ergodic dynamical systems and partial hyperbolicity. J. of Complexity, 13:125–179, 1997.\\n12. S. Smale. Mathematical problems for the next century. Math. Intelligencer, 20(2):7–15, 1998.\\n13. V. Niţ icǎ and A. Török. An open dense set of stably ergodic diffeomorphisms in a neighborhood of a non-ergodic one. Topology, 40:259–278, 2001.\\n14. Z. Xia. Homoclinic points in symplectic and volume-preserving diffeomorphism. Commun. Math. Phys., 177:435–449, 1996.\\n15. Z. Xia. Area-preserving surface diffeomorphisms. Preprint, Mathematics ArXiv: math.DS/0503223, 2004.\\n\\nDepartment of Mathematics, Northwestern University, Evanston, IL 60208 E-mail address : xia@math.northwestern.edu & zhang@math.northwestern.edu'}\n",
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['input_ids', 'attention_mask', 'ref_loss'],\n",
            "        num_rows: 9990\n",
            "    })\n",
            "    valid: Dataset({\n",
            "        features: ['input_ids', 'attention_mask', 'ref_loss'],\n",
            "        num_rows: 10\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = filtering_llama\n",
        "model_size = sum(t.numel() for t in model.parameters())\n",
        "print(f\"SFT Parameter size: {model_size/1000**2:.1f}M parameters\")\n",
        "\n",
        "trainer = Trainer(model, tokenizer, tokenized_dataset[\"train\"], tokenized_dataset[\"valid\"])\n",
        "\n",
        "\n",
        "if args.ref_model_backend == \"none\" or args.pre_compute_ref:\n",
        "    trainer.train()\n",
        "elif args.ref_model_backend == \"vllm\":\n",
        "    for epoch in range(args.epochs):\n",
        "        for step, batch in tqdm(\n",
        "            enumerate(trainer.train_dataloader, start=1+epoch*(trainer.num_training_steps//args.epochs)), total=trainer.num_training_steps\n",
        "        ):\n",
        "            if step <= trainer.step:\n",
        "                continue\n",
        "            # Request ref model (This is very slow)\n",
        "            completion = client.completions.create(\n",
        "                model=vllm_model,\n",
        "                prompt=tokenizer.batch_decode(batch[\"input_ids\"]),\n",
        "                echo=True, n=1, max_tokens=1, stream=False, logprobs=1,\n",
        "            )\n",
        "            ref_loss = [[-e for e in choice.logprobs.token_logprobs[1:-1]] for choice in completion.choices]\n",
        "            trainer.train_step(batch, ref_loss=ref_loss)\n",
        "    trainer.end_training()\n",
        "elif args.ref_model_backend == \"socket\":\n",
        "    recv_queue, send_queue = init_socket(args)\n",
        "    bar = tqdm(total=trainer.num_training_steps // args.gradient_accumulation_steps)\n",
        "    data_queue = []\n",
        "    buffer_size = 4 * args.gradient_accumulation_steps\n",
        "    for epoch in range(args.epochs):\n",
        "        for step, batch in enumerate(\n",
        "            trainer.train_dataloader, start=1+epoch*(trainer.num_training_steps//args.epochs)\n",
        "        ):\n",
        "            if step <= trainer.step:\n",
        "                continue\n",
        "            # enter queue and send request\n",
        "            data_queue.append(batch)\n",
        "            batch_input_ids = batch[\"input_ids\"].tolist()\n",
        "            send_queue.put([batch_input_ids[e][-batch['token_size'][e]:] for e in range(len(batch_input_ids))])\n",
        "            # train micro-batch\n",
        "            if step % args.gradient_accumulation_steps == 0 and step >= buffer_size:\n",
        "                if step == buffer_size:\n",
        "                    time.sleep(10)\n",
        "                for mic_i in range(args.gradient_accumulation_steps):\n",
        "                    trainer.train_step(data_queue.pop(0), ref_loss=recv_queue.get()['loss'])\n",
        "                bar.update(1)\n",
        "    trainer.end_training()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1y01wcmnmVdr",
        "outputId": "d064e4c1-a195-41c3-9c8b-aa08532477b9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SFT Parameter size: 1100.0M parameters\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241214_134809-irazn2gn</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/434446127cxc-hong-kong-university-of-science-and-technology/TinyLlama_v1.1/runs/irazn2gn' target=\"_blank\">earnest-smoke-37</a></strong> to <a href='https://wandb.ai/434446127cxc-hong-kong-university-of-science-and-technology/TinyLlama_v1.1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/434446127cxc-hong-kong-university-of-science-and-technology/TinyLlama_v1.1' target=\"_blank\">https://wandb.ai/434446127cxc-hong-kong-university-of-science-and-technology/TinyLlama_v1.1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/434446127cxc-hong-kong-university-of-science-and-technology/TinyLlama_v1.1/runs/irazn2gn' target=\"_blank\">https://wandb.ai/434446127cxc-hong-kong-university-of-science-and-technology/TinyLlama_v1.1/runs/irazn2gn</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num training steps (after // args.gradient_accumulation_steps): 312\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/9990 [00:00<?, ?it/s]LlamaModel is using LlamaSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "  0%|          | 32/9990 [00:08<36:17,  4.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 32, 'steps': 1, 'loss/train': 10.864990562200546, 'learning rate': 6.000000000000001e-08}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 65/9990 [00:14<25:23,  6.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 64, 'steps': 2, 'loss/train': 10.828778117895126, 'learning rate': 1.2000000000000002e-07}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 96/9990 [00:21<51:53,  3.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 96, 'steps': 3, 'loss/train': 10.859063357114792, 'learning rate': 1.8e-07}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|▏         | 128/9990 [00:28<33:17,  4.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 128, 'steps': 4, 'loss/train': 10.867765486240387, 'learning rate': 2.4000000000000003e-07}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 160/9990 [00:34<21:58,  7.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 160, 'steps': 5, 'loss/train': 10.859372556209564, 'learning rate': 3.0000000000000004e-07}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 192/9990 [00:41<50:06,  3.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 192, 'steps': 6, 'loss/train': 10.840717017650604, 'learning rate': 3.6e-07}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 224/9990 [00:48<39:07,  4.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 224, 'steps': 7, 'loss/train': 10.824065804481506, 'learning rate': 4.2e-07}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 256/9990 [00:55<34:06,  4.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 256, 'steps': 8, 'loss/train': 10.821516960859299, 'learning rate': 4.800000000000001e-07}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 289/9990 [01:01<33:36,  4.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 288, 'steps': 9, 'loss/train': 10.83515477180481, 'learning rate': 5.4e-07}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 320/9990 [01:07<34:12,  4.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 320, 'steps': 10, 'loss/train': 10.836535573005676, 'learning rate': 6.000000000000001e-07}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▎         | 352/9990 [01:14<33:36,  4.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 352, 'steps': 11, 'loss/train': 10.861128151416779, 'learning rate': 6.599999999999999e-07}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▍         | 384/9990 [01:21<46:01,  3.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 384, 'steps': 12, 'loss/train': 10.836581319570541, 'learning rate': 7.2e-07}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▍         | 417/9990 [01:28<26:45,  5.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 416, 'steps': 13, 'loss/train': 10.843077957630157, 'learning rate': 7.799999999999999e-07}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▍         | 449/9990 [01:34<27:45,  5.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 448, 'steps': 14, 'loss/train': 10.811795026063919, 'learning rate': 8.4e-07}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▍         | 480/9990 [01:42<48:55,  3.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 480, 'steps': 15, 'loss/train': 10.870752990245819, 'learning rate': 9e-07}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 512/9990 [01:48<25:25,  6.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 512, 'steps': 16, 'loss/train': 10.825555741786957, 'learning rate': 9.600000000000001e-07}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 545/9990 [01:55<26:08,  6.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 544, 'steps': 17, 'loss/train': 10.818235874176025, 'learning rate': 1.0200000000000002e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 576/9990 [02:01<37:19,  4.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 576, 'steps': 18, 'loss/train': 10.843534231185913, 'learning rate': 1.08e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 608/9990 [02:08<36:14,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 608, 'steps': 19, 'loss/train': 10.844286322593689, 'learning rate': 1.14e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▋         | 641/9990 [02:16<37:27,  4.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 640, 'steps': 20, 'loss/train': 10.845851838588715, 'learning rate': 1.2000000000000002e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 673/9990 [02:22<25:03,  6.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 672, 'steps': 21, 'loss/train': 10.820344537496567, 'learning rate': 1.26e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 705/9990 [02:30<30:26,  5.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 704, 'steps': 22, 'loss/train': 10.837251156568527, 'learning rate': 1.3199999999999999e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 737/9990 [02:36<28:58,  5.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 736, 'steps': 23, 'loss/train': 10.850965291261673, 'learning rate': 1.38e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|▊         | 769/9990 [02:43<35:03,  4.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 768, 'steps': 24, 'loss/train': 10.844049006700516, 'learning rate': 1.44e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|▊         | 801/9990 [02:51<26:22,  5.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 800, 'steps': 25, 'loss/train': 10.839504271745682, 'learning rate': 1.5e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|▊         | 832/9990 [02:58<37:48,  4.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 832, 'steps': 26, 'loss/train': 10.812490671873093, 'learning rate': 1.5599999999999999e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  9%|▊         | 864/9990 [03:04<35:00,  4.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 864, 'steps': 27, 'loss/train': 10.822707056999207, 'learning rate': 1.62e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  9%|▉         | 896/9990 [03:10<27:06,  5.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 896, 'steps': 28, 'loss/train': 10.848156303167343, 'learning rate': 1.68e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  9%|▉         | 928/9990 [03:17<37:49,  3.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 928, 'steps': 29, 'loss/train': 10.87329450249672, 'learning rate': 1.74e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|▉         | 960/9990 [03:23<32:33,  4.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 960, 'steps': 30, 'loss/train': 10.858996570110321, 'learning rate': 1.8e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|▉         | 993/9990 [03:30<34:08,  4.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 992, 'steps': 31, 'loss/train': 10.855849593877792, 'learning rate': 1.86e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 1025/9990 [03:36<25:11,  5.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 1024, 'steps': 32, 'loss/train': 10.851114064455032, 'learning rate': 1.9200000000000003e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 1057/9990 [03:43<29:09,  5.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 1056, 'steps': 33, 'loss/train': 10.845116645097733, 'learning rate': 1.98e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 1088/9990 [03:50<37:03,  4.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 1088, 'steps': 34, 'loss/train': 10.855424225330353, 'learning rate': 2.0400000000000004e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 1120/9990 [03:57<40:43,  3.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 1120, 'steps': 35, 'loss/train': 10.826358318328857, 'learning rate': 2.1000000000000002e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 1152/9990 [04:04<43:50,  3.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 1152, 'steps': 36, 'loss/train': 10.861707210540771, 'learning rate': 2.16e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 1185/9990 [04:11<24:40,  5.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 1184, 'steps': 37, 'loss/train': 10.825650215148926, 'learning rate': 2.22e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 1216/9990 [04:19<29:07,  5.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 1216, 'steps': 38, 'loss/train': 10.859686940908432, 'learning rate': 2.28e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 1249/9990 [04:26<27:36,  5.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 1248, 'steps': 39, 'loss/train': 10.82819852232933, 'learning rate': 2.34e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 1280/9990 [04:33<36:44,  3.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 1280, 'steps': 40, 'loss/train': 10.84010061621666, 'learning rate': 2.4000000000000003e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 1312/9990 [04:41<41:12,  3.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 1312, 'steps': 41, 'loss/train': 10.826908022165298, 'learning rate': 2.46e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 1345/9990 [04:48<26:36,  5.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 1344, 'steps': 42, 'loss/train': 10.840722858905792, 'learning rate': 2.52e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|█▍        | 1376/9990 [04:56<29:06,  4.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 1376, 'steps': 43, 'loss/train': 10.828434377908707, 'learning rate': 2.58e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|█▍        | 1408/9990 [05:03<35:02,  4.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 1408, 'steps': 44, 'loss/train': 10.843798637390137, 'learning rate': 2.6399999999999997e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|█▍        | 1441/9990 [05:10<23:39,  6.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 1440, 'steps': 45, 'loss/train': 10.84716510772705, 'learning rate': 2.7e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▍        | 1473/9990 [05:18<30:39,  4.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 1472, 'steps': 46, 'loss/train': 10.848268330097198, 'learning rate': 2.76e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▌        | 1504/9990 [05:25<37:35,  3.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 1504, 'steps': 47, 'loss/train': 10.828490674495697, 'learning rate': 2.82e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▌        | 1536/9990 [05:31<31:49,  4.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 1536, 'steps': 48, 'loss/train': 10.820629477500916, 'learning rate': 2.88e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 1568/9990 [05:39<34:23,  4.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 1568, 'steps': 49, 'loss/train': 10.840063065290451, 'learning rate': 2.9400000000000002e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 1601/9990 [05:46<25:03,  5.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 1600, 'steps': 50, 'loss/train': 10.864047408103943, 'learning rate': 3e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▋        | 1633/9990 [05:52<21:30,  6.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 1632, 'steps': 51, 'loss/train': 10.837166368961334, 'learning rate': 3.06e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 1665/9990 [05:59<24:29,  5.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 1664, 'steps': 52, 'loss/train': 10.840673714876175, 'learning rate': 3.1199999999999998e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 1697/9990 [06:05<28:36,  4.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 1696, 'steps': 53, 'loss/train': 10.825290769338608, 'learning rate': 3.18e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 1729/9990 [06:12<24:05,  5.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 1728, 'steps': 54, 'loss/train': 10.845950901508331, 'learning rate': 3.24e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|█▊        | 1760/9990 [06:20<28:58,  4.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 1760, 'steps': 55, 'loss/train': 10.842720866203308, 'learning rate': 3.3e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|█▊        | 1792/9990 [06:26<34:50,  3.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 1792, 'steps': 56, 'loss/train': 10.844473540782928, 'learning rate': 3.36e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|█▊        | 1824/9990 [06:34<36:25,  3.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 1824, 'steps': 57, 'loss/train': 10.835886120796204, 'learning rate': 3.4200000000000003e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 19%|█▊        | 1856/9990 [06:42<27:29,  4.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 1856, 'steps': 58, 'loss/train': 10.852850615978241, 'learning rate': 3.48e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 19%|█▉        | 1889/9990 [06:48<29:59,  4.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 1888, 'steps': 59, 'loss/train': 10.86500671505928, 'learning rate': 3.54e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 19%|█▉        | 1921/9990 [06:56<27:12,  4.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 1920, 'steps': 60, 'loss/train': 10.835085719823837, 'learning rate': 3.6e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|█▉        | 1953/9990 [07:03<27:40,  4.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 1952, 'steps': 61, 'loss/train': 10.82624638080597, 'learning rate': 3.66e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|█▉        | 1985/9990 [07:09<21:20,  6.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 1984, 'steps': 62, 'loss/train': 10.828345507383347, 'learning rate': 3.72e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 2017/9990 [07:16<24:03,  5.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 2016, 'steps': 63, 'loss/train': 10.860991299152374, 'learning rate': 3.7800000000000002e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 21%|██        | 2048/9990 [07:22<20:42,  6.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 2048, 'steps': 64, 'loss/train': 10.862703830003738, 'learning rate': 3.8400000000000005e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 21%|██        | 2080/9990 [07:31<37:41,  3.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 2080, 'steps': 65, 'loss/train': 10.861335963010788, 'learning rate': 3.9e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 21%|██        | 2113/9990 [07:38<21:38,  6.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 2112, 'steps': 66, 'loss/train': 10.86448410153389, 'learning rate': 3.96e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 21%|██▏       | 2144/9990 [07:44<22:43,  5.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 2144, 'steps': 67, 'loss/train': 10.803175389766693, 'learning rate': 4.0200000000000005e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|██▏       | 2176/9990 [07:50<20:29,  6.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 2176, 'steps': 68, 'loss/train': 10.841241478919983, 'learning rate': 4.080000000000001e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|██▏       | 2208/9990 [07:58<32:27,  4.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 2208, 'steps': 69, 'loss/train': 10.812302678823471, 'learning rate': 4.14e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|██▏       | 2240/9990 [08:06<31:17,  4.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 2240, 'steps': 70, 'loss/train': 10.870043218135834, 'learning rate': 4.2000000000000004e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 2272/9990 [08:14<41:46,  3.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 2272, 'steps': 71, 'loss/train': 10.85387372970581, 'learning rate': 4.26e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 2304/9990 [08:21<28:30,  4.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 2304, 'steps': 72, 'loss/train': 10.87964352965355, 'learning rate': 4.32e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 2337/9990 [08:28<28:58,  4.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 2336, 'steps': 73, 'loss/train': 10.84286916255951, 'learning rate': 4.3799999999999996e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▎       | 2368/9990 [08:34<19:52,  6.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 2368, 'steps': 74, 'loss/train': 10.845631301403046, 'learning rate': 4.44e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▍       | 2401/9990 [08:42<28:56,  4.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 2400, 'steps': 75, 'loss/train': 10.858724981546402, 'learning rate': 4.5e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▍       | 2432/9990 [08:49<28:01,  4.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 2432, 'steps': 76, 'loss/train': 10.851769924163818, 'learning rate': 4.56e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▍       | 2465/9990 [08:57<27:17,  4.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 2464, 'steps': 77, 'loss/train': 10.832778871059418, 'learning rate': 4.62e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▍       | 2497/9990 [09:05<21:52,  5.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 2496, 'steps': 78, 'loss/train': 10.852371990680695, 'learning rate': 4.68e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 2529/9990 [09:11<26:56,  4.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 2528, 'steps': 79, 'loss/train': 10.854084223508835, 'learning rate': 4.74e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 2560/9990 [09:18<29:13,  4.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 2560, 'steps': 80, 'loss/train': 10.862732350826263, 'learning rate': 4.800000000000001e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 2593/9990 [09:25<24:16,  5.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 2592, 'steps': 81, 'loss/train': 10.823377758264542, 'learning rate': 4.86e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▋       | 2624/9990 [09:32<36:51,  3.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 2624, 'steps': 82, 'loss/train': 10.813391298055649, 'learning rate': 4.92e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 27%|██▋       | 2657/9990 [09:39<28:04,  4.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 2656, 'steps': 83, 'loss/train': 10.852110981941223, 'learning rate': 4.980000000000001e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 27%|██▋       | 2689/9990 [09:46<16:59,  7.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 2688, 'steps': 84, 'loss/train': 10.849288254976273, 'learning rate': 5.04e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 27%|██▋       | 2721/9990 [09:52<18:26,  6.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 2720, 'steps': 85, 'loss/train': 10.829005628824234, 'learning rate': 5.1e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|██▊       | 2752/9990 [10:00<37:31,  3.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 2752, 'steps': 86, 'loss/train': 10.83565378189087, 'learning rate': 5.16e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|██▊       | 2784/9990 [10:06<22:10,  5.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 2784, 'steps': 87, 'loss/train': 10.831448644399643, 'learning rate': 5.22e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|██▊       | 2816/9990 [10:13<25:07,  4.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 2816, 'steps': 88, 'loss/train': 10.83793118596077, 'learning rate': 5.279999999999999e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 29%|██▊       | 2848/9990 [10:21<25:35,  4.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 2848, 'steps': 89, 'loss/train': 10.858355075120926, 'learning rate': 5.34e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 29%|██▉       | 2880/9990 [10:28<29:39,  4.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 2880, 'steps': 90, 'loss/train': 10.812722563743591, 'learning rate': 5.4e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 29%|██▉       | 2913/9990 [10:35<21:13,  5.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 2912, 'steps': 91, 'loss/train': 10.833583742380142, 'learning rate': 5.46e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 29%|██▉       | 2944/9990 [10:42<23:53,  4.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 2944, 'steps': 92, 'loss/train': 10.850065916776657, 'learning rate': 5.52e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|██▉       | 2976/9990 [10:49<32:56,  3.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 2976, 'steps': 93, 'loss/train': 10.832291543483734, 'learning rate': 5.58e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 3008/9990 [10:56<30:47,  3.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 3008, 'steps': 94, 'loss/train': 10.828934848308563, 'learning rate': 5.64e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 3040/9990 [11:04<26:44,  4.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 3040, 'steps': 95, 'loss/train': 10.837135046720505, 'learning rate': 5.7000000000000005e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 31%|███       | 3073/9990 [11:10<18:03,  6.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 3072, 'steps': 96, 'loss/train': 10.852690935134888, 'learning rate': 5.76e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 31%|███       | 3104/9990 [11:17<27:39,  4.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 3104, 'steps': 97, 'loss/train': 10.881518602371216, 'learning rate': 5.82e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 31%|███▏      | 3137/9990 [11:24<21:03,  5.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 3136, 'steps': 98, 'loss/train': 10.818445801734924, 'learning rate': 5.8800000000000005e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 3169/9990 [11:31<28:21,  4.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 3168, 'steps': 99, 'loss/train': 10.839690834283829, 'learning rate': 5.940000000000001e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 3199/9990 [11:38<23:47,  4.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 3200, 'steps': 100, 'loss/train': 10.854122459888458, 'learning rate': 6e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 3200/9990 [12:09<18:10:49,  9.64s/it]/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            " 32%|███▏      | 3233/9990 [12:17<18:02,  6.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 3232, 'steps': 101, 'loss/train': 10.854031562805176, 'learning rate': 6.0600000000000004e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 3264/9990 [12:25<20:21,  5.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 3264, 'steps': 102, 'loss/train': 10.851350992918015, 'learning rate': 6.12e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 3297/9990 [12:31<17:35,  6.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 3296, 'steps': 103, 'loss/train': 10.855982333421707, 'learning rate': 6.18e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 3329/9990 [12:39<19:20,  5.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 3328, 'steps': 104, 'loss/train': 10.841543585062027, 'learning rate': 6.2399999999999995e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 34%|███▎      | 3360/9990 [12:47<37:02,  2.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 3360, 'steps': 105, 'loss/train': 10.847760379314423, 'learning rate': 6.3e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 34%|███▍      | 3393/9990 [12:54<20:59,  5.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 3392, 'steps': 106, 'loss/train': 10.831341296434402, 'learning rate': 6.36e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 34%|███▍      | 3424/9990 [13:00<24:05,  4.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 3424, 'steps': 107, 'loss/train': 10.839267998933792, 'learning rate': 6.42e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▍      | 3456/9990 [13:08<28:26,  3.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 3456, 'steps': 108, 'loss/train': 10.842388808727264, 'learning rate': 6.48e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▍      | 3488/9990 [13:15<25:23,  4.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 3488, 'steps': 109, 'loss/train': 10.814478009939194, 'learning rate': 6.54e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▌      | 3521/9990 [13:22<18:29,  5.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 3520, 'steps': 110, 'loss/train': 10.815742701292038, 'learning rate': 6.6e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|███▌      | 3552/9990 [13:28<20:35,  5.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 3552, 'steps': 111, 'loss/train': 10.835924059152603, 'learning rate': 6.660000000000001e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|███▌      | 3584/9990 [13:36<17:24,  6.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 3584, 'steps': 112, 'loss/train': 10.825118333101273, 'learning rate': 6.72e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|███▌      | 3617/9990 [13:43<19:26,  5.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 3616, 'steps': 113, 'loss/train': 10.83254212141037, 'learning rate': 6.78e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 37%|███▋      | 3648/9990 [13:50<20:29,  5.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 3648, 'steps': 114, 'loss/train': 10.849958449602127, 'learning rate': 6.840000000000001e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 37%|███▋      | 3681/9990 [13:57<23:34,  4.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 3680, 'steps': 115, 'loss/train': 10.831632643938065, 'learning rate': 6.900000000000001e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 37%|███▋      | 3712/9990 [14:04<22:52,  4.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 3712, 'steps': 116, 'loss/train': 10.79548904299736, 'learning rate': 6.96e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 37%|███▋      | 3745/9990 [14:12<20:14,  5.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 3744, 'steps': 117, 'loss/train': 10.849985629320145, 'learning rate': 7.0200000000000006e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 38%|███▊      | 3776/9990 [14:18<26:57,  3.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 3776, 'steps': 118, 'loss/train': 10.825911521911621, 'learning rate': 7.08e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 38%|███▊      | 3809/9990 [14:26<22:41,  4.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 3808, 'steps': 119, 'loss/train': 10.849872171878815, 'learning rate': 7.14e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 38%|███▊      | 3841/9990 [14:33<18:59,  5.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 3840, 'steps': 120, 'loss/train': 10.829797595739365, 'learning rate': 7.2e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 39%|███▉      | 3872/9990 [14:41<22:12,  4.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 3872, 'steps': 121, 'loss/train': 10.850092321634293, 'learning rate': 7.26e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 39%|███▉      | 3905/9990 [14:48<17:03,  5.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 3904, 'steps': 122, 'loss/train': 10.827114343643188, 'learning rate': 7.32e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 39%|███▉      | 3936/9990 [14:54<21:56,  4.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 3936, 'steps': 123, 'loss/train': 10.807494461536407, 'learning rate': 7.3800000000000005e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|███▉      | 3968/9990 [15:02<25:46,  3.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 3968, 'steps': 124, 'loss/train': 10.830026626586914, 'learning rate': 7.44e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 4001/9990 [15:08<14:54,  6.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 4000, 'steps': 125, 'loss/train': 10.841388821601868, 'learning rate': 7.5e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 4032/9990 [15:15<27:34,  3.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 4032, 'steps': 126, 'loss/train': 10.839335024356842, 'learning rate': 7.5600000000000005e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 41%|████      | 4064/9990 [15:22<26:52,  3.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 4064, 'steps': 127, 'loss/train': 10.815602898597717, 'learning rate': 7.62e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 41%|████      | 4097/9990 [15:29<19:25,  5.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 4096, 'steps': 128, 'loss/train': 10.820350617170334, 'learning rate': 7.680000000000001e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 41%|████▏     | 4128/9990 [15:37<25:03,  3.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 4128, 'steps': 129, 'loss/train': 10.868590742349625, 'learning rate': 7.74e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 4160/9990 [15:45<22:36,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 4160, 'steps': 130, 'loss/train': 10.843205839395523, 'learning rate': 7.8e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 4193/9990 [15:52<19:20,  4.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 4192, 'steps': 131, 'loss/train': 10.815376341342926, 'learning rate': 7.860000000000001e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 4225/9990 [15:59<20:18,  4.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 4224, 'steps': 132, 'loss/train': 10.85196840763092, 'learning rate': 7.92e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 43%|████▎     | 4257/9990 [16:07<21:29,  4.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 4256, 'steps': 133, 'loss/train': 10.831437230110168, 'learning rate': 7.98e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 43%|████▎     | 4289/9990 [16:13<19:00,  5.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 4288, 'steps': 134, 'loss/train': 10.848240911960602, 'learning rate': 8.040000000000001e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 43%|████▎     | 4320/9990 [16:21<30:29,  3.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 4320, 'steps': 135, 'loss/train': 10.828668117523193, 'learning rate': 8.1e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 44%|████▎     | 4353/9990 [16:27<17:15,  5.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 4352, 'steps': 136, 'loss/train': 10.838700622320175, 'learning rate': 8.160000000000001e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 44%|████▍     | 4385/9990 [16:34<17:47,  5.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 4384, 'steps': 137, 'loss/train': 10.856267213821411, 'learning rate': 8.220000000000001e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 44%|████▍     | 4416/9990 [16:41<21:25,  4.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 4416, 'steps': 138, 'loss/train': 10.834438532590866, 'learning rate': 8.28e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▍     | 4449/9990 [16:49<19:26,  4.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 4448, 'steps': 139, 'loss/train': 10.834644347429276, 'learning rate': 8.340000000000001e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▍     | 4481/9990 [16:56<20:04,  4.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 4480, 'steps': 140, 'loss/train': 10.825913310050964, 'learning rate': 8.400000000000001e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▌     | 4513/9990 [17:03<18:30,  4.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 4512, 'steps': 141, 'loss/train': 10.8237963616848, 'learning rate': 8.459999999999999e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▌     | 4545/9990 [17:09<15:00,  6.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 4544, 'steps': 142, 'loss/train': 10.832851350307465, 'learning rate': 8.52e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 46%|████▌     | 4576/9990 [17:15<20:07,  4.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 4576, 'steps': 143, 'loss/train': 10.835674047470093, 'learning rate': 8.58e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 46%|████▌     | 4609/9990 [17:23<13:44,  6.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 4608, 'steps': 144, 'loss/train': 10.829500138759613, 'learning rate': 8.64e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 46%|████▋     | 4640/9990 [17:29<24:58,  3.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 4640, 'steps': 145, 'loss/train': 10.829071193933487, 'learning rate': 8.7e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 47%|████▋     | 4672/9990 [17:37<20:27,  4.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 4672, 'steps': 146, 'loss/train': 10.826727658510208, 'learning rate': 8.759999999999999e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 47%|████▋     | 4705/9990 [17:42<14:50,  5.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 4704, 'steps': 147, 'loss/train': 10.85247740149498, 'learning rate': 8.82e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 47%|████▋     | 4736/9990 [17:49<15:55,  5.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 4736, 'steps': 148, 'loss/train': 10.874262809753418, 'learning rate': 8.88e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|████▊     | 4768/9990 [17:56<20:23,  4.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 4768, 'steps': 149, 'loss/train': 10.833842039108276, 'learning rate': 8.939999999999999e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|████▊     | 4800/9990 [18:02<17:12,  5.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 4800, 'steps': 150, 'loss/train': 10.827384173870087, 'learning rate': 9e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|████▊     | 4832/9990 [18:09<17:07,  5.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 4832, 'steps': 151, 'loss/train': 10.834569782018661, 'learning rate': 9.06e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 49%|████▊     | 4864/9990 [18:16<15:00,  5.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 4864, 'steps': 152, 'loss/train': 10.854683578014374, 'learning rate': 9.12e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 49%|████▉     | 4896/9990 [18:23<21:15,  4.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 4896, 'steps': 153, 'loss/train': 10.80961760878563, 'learning rate': 9.18e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 49%|████▉     | 4928/9990 [18:30<19:50,  4.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 4928, 'steps': 154, 'loss/train': 10.864725023508072, 'learning rate': 9.24e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|████▉     | 4960/9990 [18:37<15:22,  5.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 4960, 'steps': 155, 'loss/train': 10.835291892290115, 'learning rate': 9.3e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|████▉     | 4993/9990 [18:45<14:58,  5.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 4992, 'steps': 156, 'loss/train': 10.869882434606552, 'learning rate': 9.36e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 5025/9990 [18:51<15:45,  5.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 5024, 'steps': 157, 'loss/train': 10.862516105175018, 'learning rate': 9.42e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 51%|█████     | 5057/9990 [18:58<16:46,  4.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 5056, 'steps': 158, 'loss/train': 10.865490287542343, 'learning rate': 9.48e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 51%|█████     | 5088/9990 [19:05<16:06,  5.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 5088, 'steps': 159, 'loss/train': 10.84646824002266, 'learning rate': 9.54e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 51%|█████▏    | 5120/9990 [19:13<14:04,  5.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 5120, 'steps': 160, 'loss/train': 10.816929519176483, 'learning rate': 9.600000000000001e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 52%|█████▏    | 5153/9990 [19:19<11:15,  7.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 5152, 'steps': 161, 'loss/train': 10.838350802659988, 'learning rate': 9.66e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 52%|█████▏    | 5185/9990 [19:25<16:19,  4.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 5184, 'steps': 162, 'loss/train': 10.825483411550522, 'learning rate': 9.72e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 52%|█████▏    | 5216/9990 [19:32<17:13,  4.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 5216, 'steps': 163, 'loss/train': 10.838863909244537, 'learning rate': 9.780000000000001e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 53%|█████▎    | 5248/9990 [19:39<13:35,  5.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 5248, 'steps': 164, 'loss/train': 10.81885826587677, 'learning rate': 9.84e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 53%|█████▎    | 5280/9990 [19:46<19:20,  4.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 5280, 'steps': 165, 'loss/train': 10.837518125772476, 'learning rate': 9.9e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 53%|█████▎    | 5312/9990 [19:55<15:40,  4.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 5312, 'steps': 166, 'loss/train': 10.829190760850906, 'learning rate': 9.960000000000001e-06}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 53%|█████▎    | 5344/9990 [20:02<20:17,  3.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 5344, 'steps': 167, 'loss/train': 10.833286970853806, 'learning rate': 1.002e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 54%|█████▍    | 5376/9990 [20:09<16:28,  4.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 5376, 'steps': 168, 'loss/train': 10.829048961400986, 'learning rate': 1.008e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 54%|█████▍    | 5408/9990 [20:16<16:09,  4.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 5408, 'steps': 169, 'loss/train': 10.822950094938278, 'learning rate': 1.0140000000000001e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 54%|█████▍    | 5440/9990 [20:24<23:08,  3.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 5440, 'steps': 170, 'loss/train': 10.833518534898758, 'learning rate': 1.02e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▍    | 5472/9990 [20:32<15:01,  5.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 5472, 'steps': 171, 'loss/train': 10.828203111886978, 'learning rate': 1.0260000000000002e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▌    | 5504/9990 [20:39<13:01,  5.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 5504, 'steps': 172, 'loss/train': 10.821724474430084, 'learning rate': 1.032e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▌    | 5537/9990 [20:46<12:57,  5.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 5536, 'steps': 173, 'loss/train': 10.792009025812149, 'learning rate': 1.0379999999999999e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 56%|█████▌    | 5569/9990 [20:52<09:43,  7.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 5568, 'steps': 174, 'loss/train': 10.81286495923996, 'learning rate': 1.044e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 56%|█████▌    | 5600/9990 [20:59<20:21,  3.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 5600, 'steps': 175, 'loss/train': 10.835395634174347, 'learning rate': 1.05e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 56%|█████▋    | 5633/9990 [21:06<15:43,  4.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 5632, 'steps': 176, 'loss/train': 10.799058675765991, 'learning rate': 1.0559999999999999e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 57%|█████▋    | 5664/9990 [21:13<11:26,  6.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 5664, 'steps': 177, 'loss/train': 10.864334434270859, 'learning rate': 1.062e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 57%|█████▋    | 5696/9990 [21:19<18:46,  3.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 5696, 'steps': 178, 'loss/train': 10.788744121789932, 'learning rate': 1.068e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 57%|█████▋    | 5729/9990 [21:27<10:53,  6.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 5728, 'steps': 179, 'loss/train': 10.830290138721466, 'learning rate': 1.074e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 58%|█████▊    | 5760/9990 [21:33<14:21,  4.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 5760, 'steps': 180, 'loss/train': 10.832281291484833, 'learning rate': 1.08e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 58%|█████▊    | 5793/9990 [21:40<14:14,  4.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 5792, 'steps': 181, 'loss/train': 10.784612268209457, 'learning rate': 1.086e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 58%|█████▊    | 5825/9990 [21:46<10:49,  6.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 5824, 'steps': 182, 'loss/train': 10.83531704545021, 'learning rate': 1.092e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|█████▊    | 5857/9990 [21:53<13:10,  5.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 5856, 'steps': 183, 'loss/train': 10.853222668170929, 'learning rate': 1.098e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|█████▉    | 5888/9990 [22:00<16:52,  4.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 5888, 'steps': 184, 'loss/train': 10.855250209569931, 'learning rate': 1.104e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|█████▉    | 5920/9990 [22:06<15:00,  4.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 5920, 'steps': 185, 'loss/train': 10.828235536813736, 'learning rate': 1.11e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|█████▉    | 5952/9990 [22:13<18:56,  3.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 5952, 'steps': 186, 'loss/train': 10.850982159376144, 'learning rate': 1.116e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|█████▉    | 5985/9990 [22:21<12:30,  5.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 5984, 'steps': 187, 'loss/train': 10.825200259685516, 'learning rate': 1.1220000000000001e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 6017/9990 [22:27<10:16,  6.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 6016, 'steps': 188, 'loss/train': 10.824714660644531, 'learning rate': 1.128e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 61%|██████    | 6048/9990 [22:35<12:19,  5.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 6048, 'steps': 189, 'loss/train': 10.850099235773087, 'learning rate': 1.134e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 61%|██████    | 6080/9990 [22:43<16:24,  3.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 6080, 'steps': 190, 'loss/train': 10.855873972177505, 'learning rate': 1.1400000000000001e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 61%|██████    | 6112/9990 [22:51<13:26,  4.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 6112, 'steps': 191, 'loss/train': 10.837818175554276, 'learning rate': 1.146e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 62%|██████▏   | 6144/9990 [22:58<17:25,  3.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 6144, 'steps': 192, 'loss/train': 10.835095077753067, 'learning rate': 1.152e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 62%|██████▏   | 6176/9990 [23:05<14:29,  4.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 6176, 'steps': 193, 'loss/train': 10.832901805639267, 'learning rate': 1.1580000000000001e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 62%|██████▏   | 6209/9990 [23:13<10:49,  5.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 6208, 'steps': 194, 'loss/train': 10.830320447683334, 'learning rate': 1.164e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 62%|██████▏   | 6241/9990 [23:19<08:45,  7.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 6240, 'steps': 195, 'loss/train': 10.8460151553154, 'learning rate': 1.1700000000000001e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 63%|██████▎   | 6273/9990 [23:26<13:30,  4.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 6272, 'steps': 196, 'loss/train': 10.852258741855621, 'learning rate': 1.1760000000000001e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 63%|██████▎   | 6304/9990 [23:33<13:57,  4.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 6304, 'steps': 197, 'loss/train': 10.82345962524414, 'learning rate': 1.182e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 63%|██████▎   | 6337/9990 [23:41<09:50,  6.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 6336, 'steps': 198, 'loss/train': 10.882315188646317, 'learning rate': 1.1880000000000001e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▍   | 6369/9990 [23:49<11:38,  5.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 6368, 'steps': 199, 'loss/train': 10.794942766427994, 'learning rate': 1.1940000000000001e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▍   | 6399/9990 [23:55<10:08,  5.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 6400, 'steps': 200, 'loss/train': 10.835767030715942, 'learning rate': 1.2e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▍   | 6400/9990 [24:26<9:15:24,  9.28s/it]/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            " 64%|██████▍   | 6433/9990 [24:34<10:44,  5.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 6432, 'steps': 201, 'loss/train': 10.838656693696976, 'learning rate': 1.2060000000000001e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▍   | 6464/9990 [24:40<13:21,  4.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 6464, 'steps': 202, 'loss/train': 10.82039189338684, 'learning rate': 1.2120000000000001e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▌   | 6497/9990 [24:46<08:35,  6.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 6496, 'steps': 203, 'loss/train': 10.87048065662384, 'learning rate': 1.2180000000000002e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▌   | 6528/9990 [24:52<08:25,  6.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 6528, 'steps': 204, 'loss/train': 10.868808656930923, 'learning rate': 1.224e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|██████▌   | 6560/9990 [25:00<16:18,  3.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 6560, 'steps': 205, 'loss/train': 10.80925253033638, 'learning rate': 1.2299999999999999e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|██████▌   | 6593/9990 [25:07<09:30,  5.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 6592, 'steps': 206, 'loss/train': 10.826950132846832, 'learning rate': 1.236e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|██████▋   | 6625/9990 [25:15<13:31,  4.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 6624, 'steps': 207, 'loss/train': 10.846235901117325, 'learning rate': 1.242e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 6656/9990 [25:22<12:46,  4.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 6656, 'steps': 208, 'loss/train': 10.856662333011627, 'learning rate': 1.2479999999999999e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 6688/9990 [25:30<07:57,  6.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 6688, 'steps': 209, 'loss/train': 10.816413760185242, 'learning rate': 1.254e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 6720/9990 [25:37<15:19,  3.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 6720, 'steps': 210, 'loss/train': 10.806274265050888, 'learning rate': 1.26e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 68%|██████▊   | 6752/9990 [25:44<12:13,  4.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 6752, 'steps': 211, 'loss/train': 10.859767138957977, 'learning rate': 1.2659999999999999e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 68%|██████▊   | 6784/9990 [25:51<11:19,  4.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 6784, 'steps': 212, 'loss/train': 10.841845095157623, 'learning rate': 1.272e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 68%|██████▊   | 6816/9990 [25:59<15:34,  3.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 6816, 'steps': 213, 'loss/train': 10.845654785633087, 'learning rate': 1.278e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 69%|██████▊   | 6848/9990 [26:06<10:38,  4.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 6848, 'steps': 214, 'loss/train': 10.834720104932785, 'learning rate': 1.284e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 69%|██████▉   | 6880/9990 [26:13<11:55,  4.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 6880, 'steps': 215, 'loss/train': 10.847507148981094, 'learning rate': 1.29e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 69%|██████▉   | 6912/9990 [26:20<12:04,  4.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 6912, 'steps': 216, 'loss/train': 10.827181816101074, 'learning rate': 1.296e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|██████▉   | 6944/9990 [26:27<12:01,  4.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 6944, 'steps': 217, 'loss/train': 10.841979026794434, 'learning rate': 1.302e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|██████▉   | 6977/9990 [26:34<10:22,  4.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 6976, 'steps': 218, 'loss/train': 10.815747886896133, 'learning rate': 1.308e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 7008/9990 [26:42<10:52,  4.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 7008, 'steps': 219, 'loss/train': 10.821479827165604, 'learning rate': 1.314e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 7041/9990 [26:49<11:13,  4.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 7040, 'steps': 220, 'loss/train': 10.85515347123146, 'learning rate': 1.32e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 71%|███████   | 7073/9990 [26:56<07:53,  6.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 7072, 'steps': 221, 'loss/train': 10.825978815555573, 'learning rate': 1.326e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 71%|███████   | 7104/9990 [27:02<13:29,  3.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 7104, 'steps': 222, 'loss/train': 10.849763870239258, 'learning rate': 1.3320000000000001e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 71%|███████▏  | 7136/9990 [27:09<09:22,  5.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 7136, 'steps': 223, 'loss/train': 10.821173429489136, 'learning rate': 1.338e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 7168/9990 [27:16<07:30,  6.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 7168, 'steps': 224, 'loss/train': 10.83676153421402, 'learning rate': 1.344e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 7201/9990 [27:24<08:59,  5.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 7200, 'steps': 225, 'loss/train': 10.832893699407578, 'learning rate': 1.3500000000000001e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 7232/9990 [27:32<13:35,  3.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 7232, 'steps': 226, 'loss/train': 10.855937033891678, 'learning rate': 1.356e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 73%|███████▎  | 7264/9990 [27:39<14:46,  3.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 7264, 'steps': 227, 'loss/train': 10.857698768377304, 'learning rate': 1.362e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 73%|███████▎  | 7296/9990 [27:46<13:45,  3.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 7296, 'steps': 228, 'loss/train': 10.849620372056961, 'learning rate': 1.3680000000000001e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 73%|███████▎  | 7328/9990 [27:53<07:11,  6.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 7328, 'steps': 229, 'loss/train': 10.852103918790817, 'learning rate': 1.374e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 74%|███████▎  | 7360/9990 [27:59<07:00,  6.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 7360, 'steps': 230, 'loss/train': 10.818010300397873, 'learning rate': 1.3800000000000002e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 74%|███████▍  | 7392/9990 [28:07<11:59,  3.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 7392, 'steps': 231, 'loss/train': 10.823863297700882, 'learning rate': 1.3860000000000001e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 74%|███████▍  | 7425/9990 [28:13<07:20,  5.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 7424, 'steps': 232, 'loss/train': 10.825352668762207, 'learning rate': 1.392e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▍  | 7457/9990 [28:20<08:10,  5.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 7456, 'steps': 233, 'loss/train': 10.832021296024323, 'learning rate': 1.3980000000000002e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▍  | 7488/9990 [28:27<10:13,  4.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 7488, 'steps': 234, 'loss/train': 10.859036892652512, 'learning rate': 1.4040000000000001e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 7520/9990 [28:36<08:28,  4.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 7520, 'steps': 235, 'loss/train': 10.870209574699402, 'learning rate': 1.4099999999999999e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▌  | 7552/9990 [28:42<10:30,  3.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 7552, 'steps': 236, 'loss/train': 10.86797720193863, 'learning rate': 1.416e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▌  | 7584/9990 [28:50<08:38,  4.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 7584, 'steps': 237, 'loss/train': 10.81364420056343, 'learning rate': 1.422e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▌  | 7616/9990 [28:57<06:57,  5.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 7616, 'steps': 238, 'loss/train': 10.826577574014664, 'learning rate': 1.428e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 77%|███████▋  | 7648/9990 [29:04<08:27,  4.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 7648, 'steps': 239, 'loss/train': 10.840562641620636, 'learning rate': 1.434e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 77%|███████▋  | 7680/9990 [29:11<07:42,  4.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 7680, 'steps': 240, 'loss/train': 10.812643945217133, 'learning rate': 1.44e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 77%|███████▋  | 7713/9990 [29:18<06:26,  5.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 7712, 'steps': 241, 'loss/train': 10.827011615037918, 'learning rate': 1.446e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 78%|███████▊  | 7744/9990 [29:25<09:39,  3.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 7744, 'steps': 242, 'loss/train': 10.847587525844574, 'learning rate': 1.452e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 78%|███████▊  | 7776/9990 [29:32<09:10,  4.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 7776, 'steps': 243, 'loss/train': 10.823823869228363, 'learning rate': 1.458e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 78%|███████▊  | 7808/9990 [29:40<09:03,  4.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 7808, 'steps': 244, 'loss/train': 10.811130613088608, 'learning rate': 1.464e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 78%|███████▊  | 7841/9990 [29:47<06:02,  5.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 7840, 'steps': 245, 'loss/train': 10.844916701316833, 'learning rate': 1.47e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 79%|███████▉  | 7872/9990 [29:53<04:56,  7.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 7872, 'steps': 246, 'loss/train': 10.849025249481201, 'learning rate': 1.4760000000000001e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 79%|███████▉  | 7904/9990 [30:01<06:18,  5.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 7904, 'steps': 247, 'loss/train': 10.801041305065155, 'learning rate': 1.482e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 79%|███████▉  | 7937/9990 [30:08<07:05,  4.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 7936, 'steps': 248, 'loss/train': 10.827695816755295, 'learning rate': 1.488e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|███████▉  | 7968/9990 [30:16<08:25,  4.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 7968, 'steps': 249, 'loss/train': 10.816309213638306, 'learning rate': 1.4940000000000001e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 8000/9990 [30:23<08:37,  3.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 8000, 'steps': 250, 'loss/train': 10.81307652592659, 'learning rate': 1.5e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 8032/9990 [30:30<09:35,  3.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 8032, 'steps': 251, 'loss/train': 10.8138727247715, 'learning rate': 1.506e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 81%|████████  | 8064/9990 [30:37<06:36,  4.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 8064, 'steps': 252, 'loss/train': 10.820229947566986, 'learning rate': 1.5120000000000001e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 81%|████████  | 8097/9990 [30:45<06:45,  4.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 8096, 'steps': 253, 'loss/train': 10.824627846479416, 'learning rate': 1.518e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 81%|████████▏ | 8128/9990 [30:52<07:47,  3.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 8128, 'steps': 254, 'loss/train': 10.815789550542831, 'learning rate': 1.524e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 82%|████████▏ | 8160/9990 [31:00<06:56,  4.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 8160, 'steps': 255, 'loss/train': 10.84738141298294, 'learning rate': 1.53e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 82%|████████▏ | 8193/9990 [31:08<04:37,  6.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 8192, 'steps': 256, 'loss/train': 10.840238988399506, 'learning rate': 1.5360000000000002e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 82%|████████▏ | 8224/9990 [31:14<05:12,  5.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 8224, 'steps': 257, 'loss/train': 10.814583361148834, 'learning rate': 1.542e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 8257/9990 [31:22<05:39,  5.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 8256, 'steps': 258, 'loss/train': 10.848556965589523, 'learning rate': 1.548e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 8288/9990 [31:28<04:12,  6.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 8288, 'steps': 259, 'loss/train': 10.839173555374146, 'learning rate': 1.554e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 8320/9990 [31:34<03:57,  7.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 8320, 'steps': 260, 'loss/train': 10.783190876245499, 'learning rate': 1.56e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|████████▎ | 8352/9990 [31:42<08:30,  3.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 8352, 'steps': 261, 'loss/train': 10.83181843161583, 'learning rate': 1.5660000000000003e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|████████▍ | 8384/9990 [31:49<06:24,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 8384, 'steps': 262, 'loss/train': 10.83598855137825, 'learning rate': 1.5720000000000002e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|████████▍ | 8416/9990 [31:56<06:36,  3.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 8416, 'steps': 263, 'loss/train': 10.850811630487442, 'learning rate': 1.578e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|████████▍ | 8448/9990 [32:02<03:44,  6.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 8448, 'steps': 264, 'loss/train': 10.840368270874023, 'learning rate': 1.584e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|████████▍ | 8480/9990 [32:08<05:01,  5.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 8480, 'steps': 265, 'loss/train': 10.828412532806396, 'learning rate': 1.59e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|████████▌ | 8512/9990 [32:15<05:52,  4.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 8512, 'steps': 266, 'loss/train': 10.834470331668854, 'learning rate': 1.596e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|████████▌ | 8544/9990 [32:22<04:11,  5.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 8544, 'steps': 267, 'loss/train': 10.814966946840286, 'learning rate': 1.6020000000000002e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|████████▌ | 8577/9990 [32:30<05:34,  4.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 8576, 'steps': 268, 'loss/train': 10.825398355722427, 'learning rate': 1.6080000000000002e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|████████▌ | 8608/9990 [32:37<04:06,  5.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 8608, 'steps': 269, 'loss/train': 10.829819947481155, 'learning rate': 1.614e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|████████▋ | 8641/9990 [32:44<04:31,  4.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 8640, 'steps': 270, 'loss/train': 10.841299921274185, 'learning rate': 1.62e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 87%|████████▋ | 8672/9990 [32:51<03:33,  6.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 8672, 'steps': 271, 'loss/train': 10.824164748191833, 'learning rate': 1.626e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 87%|████████▋ | 8704/9990 [32:59<05:36,  3.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 8704, 'steps': 272, 'loss/train': 10.829496622085571, 'learning rate': 1.6320000000000003e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 87%|████████▋ | 8736/9990 [33:06<05:02,  4.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 8736, 'steps': 273, 'loss/train': 10.833998262882233, 'learning rate': 1.6380000000000002e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|████████▊ | 8768/9990 [33:14<04:07,  4.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 8768, 'steps': 274, 'loss/train': 10.785600990056992, 'learning rate': 1.6440000000000002e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|████████▊ | 8801/9990 [33:21<04:09,  4.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 8800, 'steps': 275, 'loss/train': 10.814446449279785, 'learning rate': 1.65e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|████████▊ | 8833/9990 [33:29<03:33,  5.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 8832, 'steps': 276, 'loss/train': 10.818836569786072, 'learning rate': 1.656e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 89%|████████▊ | 8864/9990 [33:36<04:18,  4.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 8864, 'steps': 277, 'loss/train': 10.847730696201324, 'learning rate': 1.6620000000000004e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 89%|████████▉ | 8897/9990 [33:43<03:15,  5.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 8896, 'steps': 278, 'loss/train': 10.824070990085602, 'learning rate': 1.6680000000000003e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 89%|████████▉ | 8929/9990 [33:49<03:16,  5.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 8928, 'steps': 279, 'loss/train': 10.827648758888245, 'learning rate': 1.6740000000000002e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|████████▉ | 8961/9990 [33:56<04:00,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 8960, 'steps': 280, 'loss/train': 10.823884785175323, 'learning rate': 1.6800000000000002e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 8992/9990 [34:04<03:58,  4.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 8992, 'steps': 281, 'loss/train': 10.844423860311508, 'learning rate': 1.686e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 9025/9990 [34:11<04:01,  3.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 9024, 'steps': 282, 'loss/train': 10.826735883951187, 'learning rate': 1.6919999999999997e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 91%|█████████ | 9056/9990 [34:17<02:42,  5.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 9056, 'steps': 283, 'loss/train': 10.862271219491959, 'learning rate': 1.698e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 91%|█████████ | 9088/9990 [34:24<04:21,  3.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 9088, 'steps': 284, 'loss/train': 10.838291466236115, 'learning rate': 1.704e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 91%|█████████▏| 9121/9990 [34:31<02:38,  5.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 9120, 'steps': 285, 'loss/train': 10.814885377883911, 'learning rate': 1.71e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 9153/9990 [34:39<03:13,  4.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 9152, 'steps': 286, 'loss/train': 10.832755476236343, 'learning rate': 1.716e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 9184/9990 [34:47<03:20,  4.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 9184, 'steps': 287, 'loss/train': 10.830815583467484, 'learning rate': 1.7219999999999998e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 9216/9990 [34:54<02:43,  4.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 9216, 'steps': 288, 'loss/train': 10.83811628818512, 'learning rate': 1.728e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 93%|█████████▎| 9248/9990 [35:01<02:45,  4.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 9248, 'steps': 289, 'loss/train': 10.830752491950989, 'learning rate': 1.734e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 93%|█████████▎| 9280/9990 [35:08<02:08,  5.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 9280, 'steps': 290, 'loss/train': 10.81725624203682, 'learning rate': 1.74e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 93%|█████████▎| 9313/9990 [35:15<01:58,  5.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 9312, 'steps': 291, 'loss/train': 10.84562799334526, 'learning rate': 1.746e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 94%|█████████▎| 9344/9990 [35:22<02:07,  5.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 9344, 'steps': 292, 'loss/train': 10.826175689697266, 'learning rate': 1.7519999999999998e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 94%|█████████▍| 9376/9990 [35:29<02:31,  4.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 9376, 'steps': 293, 'loss/train': 10.814332157373428, 'learning rate': 1.758e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 94%|█████████▍| 9409/9990 [35:35<01:50,  5.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 9408, 'steps': 294, 'loss/train': 10.832572400569916, 'learning rate': 1.764e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 94%|█████████▍| 9440/9990 [35:42<01:44,  5.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 9440, 'steps': 295, 'loss/train': 10.830223798751831, 'learning rate': 1.77e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▍| 9472/9990 [35:50<02:27,  3.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 9472, 'steps': 296, 'loss/train': 10.829795181751251, 'learning rate': 1.776e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▌| 9504/9990 [35:58<01:25,  5.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 9504, 'steps': 297, 'loss/train': 10.854274541139603, 'learning rate': 1.782e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▌| 9536/9990 [36:04<02:21,  3.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 9536, 'steps': 298, 'loss/train': 10.837619543075562, 'learning rate': 1.7879999999999998e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 9568/9990 [36:11<01:29,  4.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 9568, 'steps': 299, 'loss/train': 10.833034425973892, 'learning rate': 1.794e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 9599/9990 [36:18<01:01,  6.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 9600, 'steps': 300, 'loss/train': 10.840922862291336, 'learning rate': 1.8e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 9600/9990 [36:51<1:05:50, 10.13s/it]/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            " 96%|█████████▋| 9633/9990 [36:58<01:15,  4.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 9632, 'steps': 301, 'loss/train': 10.880121558904648, 'learning rate': 1.806e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 97%|█████████▋| 9665/9990 [37:05<01:05,  4.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 9664, 'steps': 302, 'loss/train': 10.821010768413544, 'learning rate': 1.812e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 97%|█████████▋| 9696/9990 [37:13<01:27,  3.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 9696, 'steps': 303, 'loss/train': 10.806696981191635, 'learning rate': 1.818e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 97%|█████████▋| 9728/9990 [37:20<01:12,  3.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 9728, 'steps': 304, 'loss/train': 10.823319494724274, 'learning rate': 1.824e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 9760/9990 [37:28<00:47,  4.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 9760, 'steps': 305, 'loss/train': 10.831032156944275, 'learning rate': 1.83e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 9793/9990 [37:34<00:33,  5.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 9792, 'steps': 306, 'loss/train': 10.816836923360825, 'learning rate': 1.836e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 9824/9990 [37:41<00:29,  5.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 9824, 'steps': 307, 'loss/train': 10.858855158090591, 'learning rate': 1.842e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▊| 9856/9990 [37:49<00:28,  4.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 9856, 'steps': 308, 'loss/train': 10.848946571350098, 'learning rate': 1.848e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▉| 9889/9990 [37:57<00:17,  5.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 9888, 'steps': 309, 'loss/train': 10.81046238541603, 'learning rate': 1.854e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▉| 9920/9990 [38:04<00:21,  3.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 9920, 'steps': 310, 'loss/train': 10.806109517812729, 'learning rate': 1.86e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████▉| 9953/9990 [38:12<00:07,  4.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 9952, 'steps': 311, 'loss/train': 10.823011636734009, 'learning rate': 1.866e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████▉| 9984/9990 [38:18<00:01,  4.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'samples': 9984, 'steps': 312, 'loss/train': 10.812248528003693, 'learning rate': 1.872e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9990/9990 [38:20<00:00,  4.34it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "        .wandb-row {\n",
              "            display: flex;\n",
              "            flex-direction: row;\n",
              "            flex-wrap: wrap;\n",
              "            justify-content: flex-start;\n",
              "            width: 100%;\n",
              "        }\n",
              "        .wandb-col {\n",
              "            display: flex;\n",
              "            flex-direction: column;\n",
              "            flex-basis: 100%;\n",
              "            flex: 1;\n",
              "            padding: 10px;\n",
              "        }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>learning_rate</td><td>▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇███</td></tr><tr><td>train_loss</td><td>▇▄▅▅▇▅▆▅▆▆▅▆▆▄▄▅▇▄▄▇▃▅▄▂▃▆▆▃▇█▆▁▃▂▃▆▅▃▆▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>learning_rate</td><td>2e-05</td></tr><tr><td>train_loss</td><td>10.81225</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">earnest-smoke-37</strong> at: <a href='https://wandb.ai/434446127cxc-hong-kong-university-of-science-and-technology/TinyLlama_v1.1/runs/irazn2gn' target=\"_blank\">https://wandb.ai/434446127cxc-hong-kong-university-of-science-and-technology/TinyLlama_v1.1/runs/irazn2gn</a><br/> View project at: <a href='https://wandb.ai/434446127cxc-hong-kong-university-of-science-and-technology/TinyLlama_v1.1' target=\"_blank\">https://wandb.ai/434446127cxc-hong-kong-university-of-science-and-technology/TinyLlama_v1.1</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241214_134809-irazn2gn/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.cuda.empty_cache()\n",
        "# print(os.environ['HF_HOME'])"
      ],
      "metadata": {
        "id": "hQXQYmZcpLEO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir = \"./mymodel\"\n",
        "model.save_pretrained(dir)\n",
        "tokenizer.save_pretrained(dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a25p_8FjqGM",
        "outputId": "7ee7b6e2-eca6-4625-88fc-87e2fe71b367"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./mymodel/tokenizer_config.json',\n",
              " './mymodel/special_tokens_map.json',\n",
              " './mymodel/tokenizer.model',\n",
              " './mymodel/added_tokens.json',\n",
              " './mymodel/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(\"/content/math-evaluation-harness\")\n",
        "print(os.getcwd())\n",
        "# !pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2q73qM5kfSR",
        "outputId": "f23fe70a-44f5-4693-f8b7-dd3849883a15"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/math-evaluation-harness\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash scripts/run_eval.sh deepseek-math \"../mymodel\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWWM7XHakm-b",
        "outputId": "204d77c7-d0e7-40eb-cdff-7211c573317f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+ PROMPT_TYPE=deepseek-math\n",
            "+ MODEL_NAME_OR_PATH=../mymodel\n",
            "+ OUTPUT_DIR=../mymodel/math_eval\n",
            "+ DATA_NAMES=gsm8k,minerva_math\n",
            "+ SPLIT=test\n",
            "+ NUM_TEST_SAMPLE=-1\n",
            "+ CUDA_VISIBLE_DEVICES=0\n",
            "+ TOKENIZERS_PARALLELISM=false\n",
            "+ python3 -u math_eval.py --model_name_or_path ../mymodel --output_dir ../mymodel/math_eval --data_names gsm8k,minerva_math --split test --prompt_type deepseek-math --num_test_sample -1 --seed 0 --temperature 0 --n_sampling 1 --top_p 1 --start 0 --end -1 --use_vllm --save_outputs\n",
            "2024-12-14 14:29:42.945052: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-12-14 14:29:42.961946: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-14 14:29:42.983386: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-14 14:29:42.989854: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-14 14:29:43.005134: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-14 14:29:44.219386: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Random seed set as 0\n",
            "INFO 12-14 14:29:46 config.py:1664] Downcasting torch.float32 to torch.float16.\n",
            "INFO 12-14 14:29:55 llm_engine.py:237] Initializing an LLM engine (v0.6.3.post1) with config: model='../mymodel', speculative_config=None, tokenizer='../mymodel', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=2048, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=../mymodel, num_scheduler_steps=1, chunked_prefill_enabled=False multi_step_stream_outputs=True, enable_prefix_caching=False, use_async_output_proc=True, use_cached_outputs=False, mm_processor_kwargs=None)\n",
            "INFO 12-14 14:29:56 model_runner.py:1056] Starting to load model ../mymodel...\n",
            "Loading safetensors checkpoint shards: 100% 1/1 [00:00<00:00,  1.44it/s]\n",
            "INFO 12-14 14:29:57 model_runner.py:1067] Loading model weights took 2.0512 GB\n",
            "INFO 12-14 14:29:58 gpu_executor.py:122] # GPU blocks: 98421, # CPU blocks: 11915\n",
            "INFO 12-14 14:29:58 gpu_executor.py:126] Maximum concurrency for 2048 tokens per request: 768.91x\n",
            "INFO 12-14 14:30:01 model_runner.py:1395] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
            "INFO 12-14 14:30:01 model_runner.py:1399] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
            "INFO 12-14 14:30:23 model_runner.py:1523] Graph capturing finished in 22 secs.\n",
            "==================================================\n",
            "data: gsm8k  ,remain samples: 1319\n",
            "{'question': \"Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\", 'answer': 'Janet sells 16 - 3 - 4 = <<16-3-4=9>>9 duck eggs a day.\\nShe makes 9 * 2 = $<<9*2=18>>18 every day at the farmer’s market.\\n#### 18', 'idx': 0}\n",
            "  0% 0/1319 [00:00<?, ?it/s]User: Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\n",
            "Please reason step by step, and put your final answer within \\boxed{}.\n",
            "\n",
            "Assistant:\n",
            "100% 1319/1319 [00:02<00:00, 442.35it/s]\n",
            "Stop words: ['</s>']\n",
            "-------------------- Epoch 0\n",
            "Processed prompts: 100% 1319/1319 [03:15<00:00,  6.76it/s, est. speed input: 631.87 toks/s, output: 6815.27 toks/s]\n",
            "-------------------- Epoch 1\n",
            "Unsolved samples: 0\n",
            "Execute: 100% 1319/1319 [00:03<00:00, 390.86it/s]\n",
            "Evaluate: 100% 1319/1319 [00:00<00:00, 5600.35it/s]\n",
            "{'num_samples': 1319, 'num_scores': 1319, 'timeout_samples': 0, 'empty_samples': 943, 'acc': 0.4}\n",
            "Saved to ../mymodel/math_eval/gsm8k/test_deepseek-math_-1_seed0_t0.0_s0_e-1.jsonl\n",
            "==================================================\n",
            "data: minerva_math  ,remain samples: 500\n",
            "{'idx': 0, 'problem': 'Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\\\\theta),$ where $r > 0$ and $0 \\\\le \\\\theta < 2 \\\\pi.$', 'solution': 'We have that $r = \\\\sqrt{0^2 + 3^2} = 3.$  Also, if we draw the line connecting the origin and $(0,3),$ this line makes an angle of $\\\\frac{\\\\pi}{2}$ with the positive $x$-axis.\\n\\n[asy]\\nunitsize(0.8 cm);\\n\\ndraw((-0.5,0)--(3.5,0));\\ndraw((0,-0.5)--(0,3.5));\\ndraw(arc((0,0),3,0,90),red,Arrow(6));\\n\\ndot((0,3), red);\\nlabel(\"$(0,3)$\", (0,3), W);\\ndot((3,0), red);\\n[/asy]\\n\\nTherefore, the polar coordinates are $\\\\boxed{\\\\left( 3, \\\\frac{\\\\pi}{2} \\\\right)}.$', 'answer': '\\\\left( 3, \\\\frac{\\\\pi}{2} \\\\right)', 'subject': 'Precalculus', 'level': 2, 'unique_id': 'test/precalculus/807.json'}\n",
            "  0% 0/500 [00:00<?, ?it/s]User: Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\\theta),$ where $r > 0$ and $0 \\le \\theta < 2 \\pi.$\n",
            "Please reason step by step, and put your final answer within \\boxed{}.\n",
            "\n",
            "Assistant:\n",
            "100% 500/500 [00:02<00:00, 199.54it/s]\n",
            "Stop words: ['</s>']\n",
            "-------------------- Epoch 0\n",
            "Processed prompts: 100% 500/500 [01:15<00:00,  6.59it/s, est. speed input: 663.66 toks/s, output: 6704.56 toks/s]\n",
            "-------------------- Epoch 1\n",
            "Unsolved samples: 0\n",
            "Execute: 100% 500/500 [00:01<00:00, 391.73it/s]\n",
            "Evaluate: 100% 500/500 [00:01<00:00, 465.53it/s]\n",
            "{'num_samples': 500, 'num_scores': 500, 'timeout_samples': 0, 'empty_samples': 351, 'acc': 0.8}\n",
            "Saved to ../mymodel/math_eval/minerva_math/test_deepseek-math_-1_seed0_t0.0_s0_e-1.jsonl\n",
            "gsm8k       \tminerva_math\tavg         \n",
            "0.4         \t0.8         \t0.6         \n"
          ]
        }
      ]
    }
  ]
}